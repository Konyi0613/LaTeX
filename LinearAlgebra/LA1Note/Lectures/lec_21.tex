\lecture{21}{26 Nov. 10:20}{}
\begin{remark}
    From now on, the note is not the lecture note since I didn't go to the lecture.
\end{remark}

\section{Cyclic Subspaces and Annihilators}
\begin{definition}
    If \(\alpha \) is a any vector in \(V\), the \(T\)-cyclic subspace generated by \(\alpha \) is the subspce \(Z(\alpha ; T)\) of all vectors of the form \(g(T)\alpha \), \(g \in F[x]\). If \(Z(\alpha ; T) = V\), then \(\alpha \) is called a cyclic vector for \(T\).          
\end{definition}

\begin{remark}
    Another way to describe \(Z(\alpha ; T)\) is that 
    \[
        Z(\alpha ; T) = \mathrm{span} \left\{ T^k \alpha  \right\}_{k \ge 0},  
    \] 
    and thus \(\alpha \) is a cyclic vector for \(T\) if and only if these vectors span \(V\). However, the general operator \(T\) has no cyclic vector.    
\end{remark}

\begin{definition}
    If \(\alpha \) is any vector in \(V\), the \(T\)-annihilator of \(\alpha \) is the ideal \(M(\alpha ; T)\) in \(F[x]\) consisting of all polynomials \(g\) over \(F\) such that \(g(T)\alpha = 0\). The unique moic polynomial \(p_\alpha \) which generates this ideal will also be called the \(T\)-annihilator of \(\alpha \).            
\end{definition}

\begin{remark}
    \(\deg p_\alpha > 0\) unless \(\alpha \) is the zero vector.  
\end{remark}

\begin{theorem}
    Let \(\alpha \) be any non-zero vector in \(V\) and let \(p_\alpha \) be the \(T\)-annihilator of \(\alpha \), then 
    \begin{itemize}
        \item [(i)] The degree of \(p_\alpha \) is equal to the dimension of the cyclic subspace \(Z(\alpha ; T)\). 
        \item [(ii)] If the degree of \(p_\alpha \) is \(k\), then the vectors \(\alpha, T;a, \dots , T^{k-1}\alpha  \) form a basis for \(Z(\alpha ; T)\). 
        \item [(iii)] If \(U\) is the linear operator on \(Z(\alpha ; T)\) induced by \(T\), then the minimal polynomial for \(U\) is \(p_\alpha \).           
    \end{itemize}     
\end{theorem}
\begin{proof}
    Let \(g \in F[x]\), then \(g = p_\alpha q + r\), where either \(r = 0\) or \(\deg(r) < \deg p_\alpha = k\). The polynomial \(p_\alpha q \in \mathrm{Ann}_T (\alpha ) \), so 
    \[
        g(T)\alpha = r(T) \alpha .
    \]      
    Since \(r = 0\) or \(\deg(r) < k\), the vector \(r(T)\alpha \) is a linear combination of the vectors \(\alpha , T \alpha , \dots T^{k-1} \alpha \), and thus 
    \[
        g(T) \alpha = r(T) \alpha \in \mathrm{span}\left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\}.  
    \]   
    Since \(g\) can be arbitrary polynomial of \(F[x]\), so 
    \[
        Z(\alpha ; T) \subseteq \mathrm{span} \left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\},
    \]
    and
    \[
        \mathrm{span} \left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\} \subseteq Z(\alpha ; T)
    \] is trivial, so
    \[
        Z(\alpha ; T) = \mathrm{span} \left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\}.
    \]
    Note that the set \(\left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\} \) is linearly independent, otherwise if 
    \[
        \sum_{i=0}^{k-1} \beta _i T^i \alpha = 0, 
    \] where \(\beta _i\) are not all zeros, then 
    \[
        d(x) = \sum_{i=0}^{k-1} \beta _i x^i \in \mathrm{Ann}_T(\alpha ),  
    \] but \(\deg d \le k - 1 < k = \deg p_\alpha \), so this is impossible. Hence, 
    \[
        \left\{ \alpha , T \alpha , \dots , T^{k-1} \alpha  \right\} 
    \] is a basis of \(Z(\alpha ; T)\), and thus we showed (i) and (ii). Now we show (c). Note that 
    \[
        p_\alpha (U) \left( g(T) \alpha  \right) = p_\alpha (T) g(T) \alpha  = g(T) p_\alpha (T) \alpha = g(T) 0 = 0. 
    \]
    Hence, \(p_\alpha (U) = 0\). Now if \(h \in F[x]\) with \(\deg h < k\) and \(h(U) = 0\), then we know \(h(U) \alpha = h(T) \alpha = 0\), so \(h \in \mathrm{Ann}_T(\alpha ) \) and thus \(p_\alpha \mid h\), so this is impossible since \(\deg p_\alpha > \deg h\). Hence, \(\deg m_U \ge k\) and thus \(m_U = p_\alpha \).         
\end{proof}

\begin{corollary}
    If \(V = Z(\alpha ; T)\) and \(T \in \mathcal{L} (V)\), then \(\deg m_T(x) = \dim V\). Also, since \(\dim V = \deg \mathrm{ch}_T(x) \), so we have \(m_T(x) = \mathrm{ch}_T(x) \) since \(m_T(x) \mid \mathrm{ch}_T(x) \) and they are both monic.      
\end{corollary}

Now if \(U \in \mathcal{L} (W)\) where \(\dim W = k\) and \(W = Z(\alpha ; U)\), then we know 
\[
    \alpha , U \alpha , \dots , U^{k-1} \alpha 
\]  
form a basis for \(W\), and the annihilator \(p_\alpha \) of \(\alpha \) is \(m_U(x) = \mathrm{ch}_U(x) \) by the above corollary. If we let \(\alpha _i = U^{i-1} \alpha \) for \(i = 1, 2, \dots , k\), then suppose \(\mathcal{B} = \left\{ \alpha _1, \dots , \alpha _k \right\} \), we know the action of \(U\) on \(\mathcal{B} \) is 
\begin{align*}
    U \alpha _i &= \alpha _{i+1} \text{ for } i = 1, \dots , k - 1 \\
    U \alpha _k &= -c_0 \alpha _1 - c_1 \alpha _2 - \dots - c_{k-1} \alpha _k
\end{align*} 
where \(p_\alpha  = c_0 + c_1 x + \dots + c_{k-1} x^{k-1} + x^k\). The expression for \(U \alpha _k\) is true since \(p_\alpha (U) \alpha = 0\). Hence, 
\[
    [U]_{\mathcal{B} } = \begin{pmatrix}
        0 & 0 & \cdots & 0 & -c_0  \\
        1 & 0 & \cdots & 0 & -c_1  \\
        0 & 1 & \cdots & 0 & -c_2  \\
        \vdots & \vdots & \ddots & \vdots &  \vdots \\
        0 & 0 & \cdots & 1 & -c_{k-1}  \\
    \end{pmatrix},
\]            
which is called the companion matrix of the monic polynomial \(p_\alpha \). 

\begin{theorem} \label{thm: U has cyclic vector iff there is some ordered basis can represent U to the companion matrix of mU(x)}
    If \(U \in \mathcal{L} (W)\) where \(\dim W < \infty \), then \(U\) has a cyclic vector if and only if there is some ordered basis for \(W\) in which \(U\) is represented by the companion matrix of \(m_U(x)\).      
\end{theorem}
\begin{proof}
    We have shown that if \(U\) has a cyclic vector, then there is some ordered basis for \(W\) in which \(U\) is represented by the companion matrix of \(m_U(x)\).
    
    Now if \([U]_B\) is the companion matrix of \(m_U(x)\), then we know 
    \[
        B = \left\{ \alpha , U \alpha , \dots , U^{k-1} \alpha  \right\} 
    \] where \(k = \dim W\). 
\end{proof}

\begin{corollary}
    If \(A\) is the companion matrix of a monic polynomial \(p\), then \(p\) is both \(m_A(x)\) and \(\mathrm{ch}_A(x) \).     
\end{corollary}
\begin{proof}
    If we regard \(A\) as the matrix representation of \(T \in \mathcal{L} (V)\) with respect to the standard basis, then we know \(V = Z(\alpha ; T)\) for some \(\alpha \), and thus \(m_T(x) = \mathrm{ch}_T(x) \). Also, we can check this matrix's characteristic polynomial is \(p\) by direct computing.      
\end{proof}

\section{Cyclic Decompositions and the Rational Form}
The primary purpose of this section is to prove that if \(T\) is any linear operator on a finite-dimensional vector space \(V\), then there exist vectors \(\alpha _1, \dots , \alpha _r\) in \(V\) s.t. 
\[
    V = Z(\alpha _1; T) \oplus Z(\alpha _2; T) \oplus \dots \oplus Z(\alpha_r; T).
\]    











\section{The Jordan Form}
Suppose \(N\) is a nilpotent linear operator on the finite-dimensional space \(V\). Then suppose 
\[
    V = Z(\alpha _1; N) \oplus Z(\alpha _2; N) \oplus \dots \oplus Z(\alpha_r; N)
\]  
where \(p_1, p_2, \dots , p_r\) are the \(N\)-annihilaotrs of \(\alpha _1, \dots , \alpha _r\) and \(p_{i+1} \mid p_i\) for \(i = 1,2,\dots ,r-1\) (by the theorem in previous section). Since \(N\) is nilpotent, the minimal polynomial is \(x^k\) for some \(k \le n\). Thus, each \(p_i\) is of the form \(p_i = x^{k_i}\) and the divisibility condition says
\[
    k_1 \ge k_2 \ge \dots \ge k_r.
\]       
Note that we must have \(k_1 = k\) since \(m_N(x) = x^k\) and \(m_N(N)u = 0\) for all \(u \in Z(\alpha _i ; N)\) for all \(i = 1,2,\dots ,r\) and \(k\) should be the smallest number satisfying this condition. Also, \(k_r \ge 1\). The companion matrix of \(x^{k_i}\) is the \(k_i \times k_i\) matrix 
\[
    A_i = \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & 0  \\
    \end{pmatrix},
\]         
so we know there exists an ordered basis of \(V\) in which the matrix of \(N\) is the direct product of \(A_i\)s for \(i = 1,2,\dots ,r\), where the size of \(A_i\)s decrease as \(i\) increases. Hence, one sees from this that associated with a nilpotent \(n \times n\) matrix is a positive integer \(r\) and \(r\) positive integers \(k_1, k_2, \dots , k_r\) s.t.
\[
    k_1 + k_2 + \dots + k_r = n \text{ and } k_i \ge k_{i+1}, 
\]           
and these positive integers determine the rational form of the matrix, i.e. determine the matrix up to similarity. 

\begin{proposition}
    \(r = \nu (N)\).  
\end{proposition}
\begin{proof}
    Since \([N] \sim A_1 \oplus A_2 \oplus \dots \oplus A_r\) where each \(A_i\) contributes one to the nullity, so the nullity of \(N\) is \(r\).    
\end{proof}

\begin{remark}
    \[
        \left\{ N^{k_1 - 1} \alpha _1, N^{k_2 - 1} \alpha _2, \dots , N^{k_r - 1} \alpha _r \right\} 
    \]
    form a basis of \(\ker N\) since \(N^{k_i} \alpha _i = 0\) and this set is linearly independent (since \(V\) is the direct product of \(Z(\alpha _i ; N)\)).  
\end{remark}

Hence, suppose \(\alpha \in \ker N\), then we know 
\[
    \alpha = f_1(N) \alpha _1 + \dots + f_r(N) \alpha _r
\] where \(f_i\) is a polynomial, the degree of which we may assume is less than \(k_i\). Since \(N \alpha = 0\), so we have 
\[
    0 = N \alpha = N (f_1(N)) \alpha _1 + \dots + N(f_r(N)) \alpha _r,
\]   
and since \(N(f_i(N)) \alpha _i \in Z(\alpha _i; N)\), so we know 
\[
    0 = N(f_i(N))\alpha _i = ((xf_i)(N)) \alpha _i
\] for all \(i\). Thus, \(x^{k_i} \mid x f_i\), so \(\deg (f_i) \ge k_i - 1\), so \(f_i = c_i x^{k_i - 1} \), where \(c_i\) is some scalar. But then
\[
    \alpha = c_1 \left( x^{k_1 - 1} \alpha _1 \right) + \dots + c_r \left( x^{k_r - 1} \alpha _r \right). 
\]     
This gives an alternative way to show that 
\[
    \left\{ N^{k_1 - 1} \alpha _1, \dots , N^{k_r - 1} \alpha _r \right\} 
\] form a basis of \(\ker N\). 

Now what we want to do is to combine our findings about nilpotent operators or matrices with the primary decomposition theorem.  The situation is this: Suppose \(T \in \mathcal{L} (V)\) and 
\[
    \mathrm{ch}_T(x) = (x - c_1)^{d_1} \dots (x - c_k)^{d_k}, 
\] where \(c_i \neq c_j\) for all \(i \neq j\) and \(d_i \ge 1\) for all \(i\). Then
\[
    m_T(x) = (x - c_1)^{r_1} \dots (x - c_k)^{r_k},
\]    
where \(1 \le r_i \le d_i\). If \(W_i = \ker \left( T - c_i I \right)^{r_i} \), then the primary decomposition theorem tells us 
\[
    V = W_1 \oplus \dots \oplus W_k,
\]  
ans that the operaotr \(T_i\) induced on \(W_i\) by \(T\) has 
\[
    m_{T_i}(x) = (x - c_i)^{r_i}.
\]   
Let \(N_i = T_i - c_i I\) where \(N_i \in \mathcal{L} (W_i)\), then \(N_i \) is nilpotent since 
\[
    0 = m_{T_i}(T_i) = (T_i - c_i I)^{r_i} = N_i^{r_i}
\]   
and 
\[
    m_{N_i}(x) = x^{r_i}.
\]
Hence, we know \(T_i = N_i + c_i I \) and if we choose a basis for the subspace \(W_i\) corresponding to the cyclic decomposition for the nilpotent operator \(N_i\), then 
\[
    [T_i] \sim \bigoplus \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & 0  \\
    \end{pmatrix} + c_i I = \bigoplus \begin{pmatrix}
        c_i & 0 & \cdots & 0 & 0  \\
        1 & c_i & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & c_i  \\
    \end{pmatrix}.
\]  
Hence, if we pick all the basis for the \(W_i\) together, we obtain an ordered basis for \(V\). Let us describe hte matrix \(A\) of \(T\) in this ordered basis, then 
\[
    A = \begin{pmatrix}
        A_1 & 0 & \cdots & 0  \\
        0 & A_2 & \cdots & 0  \\
        \vdots & \vdots & \ddots & \vdots  \\
        0 & 0 & \cdots & A_k  \\
    \end{pmatrix}.
\]  
Each
\[
    A_i = \begin{pmatrix}
        J_1(c_i) &  &  &   \\
         & J_2(c_i) &  &   \\
         &  & \ddots &   \\
         &  &  & J_{n_i}(c_i)  \\
    \end{pmatrix}
\] where each \(J_s(c_i)\) is a Jordan block with characteristic value \(c_i\). In this case, we call this \(A\) is in Jordan form. 

\begin{remark}
    We can decompose \(N_i\) into the direct product of many companion matrix of monic polynomial of the form \(x^z\) since we can decompose \(W_i\) into the direct product of many \(N_i\)-cyclic subspace and suppose
    \[
        W_i = Z(\beta _{i1}; N_i) \oplus \dots \oplus Z(\beta _{i n_i}; N_i),
    \] 
    then by \autoref{thm: U has cyclic vector iff there is some ordered basis can represent U to the companion matrix of mU(x)} we know there exists basis \(B_{il}\) s.t. 
    \[
        [N_i]_{\bigcup_{l=1}^{n_i} B_{il}} = \bigoplus \begin{pmatrix}
            0 &  &  &   \\
            1 & 0 &  &   \\
            \vdots & \ddots & \ddots &   \\
            0 & \cdots & 1 & 0  \\
        \end{pmatrix}
    \]    
\end{remark}

\begin{remark}
    We have just pointed out that if \(T\) is a linear operator for which \(\mathrm{ch}_T(x) \) splits over the field, then there is an ordered basis for \(V\) in which \(T\) is represented by a matrix which is in Jordan form.     
\end{remark}

We should like to show now that this matrix is something uniquely assosciated with \(T\), up to the order in which the characteristic values of \(T\) is written down. In other words, if two matrices both in Jordan form and they are similar, then they can differ only in that the order of scalar \(c_i\) is different. 

The uniqueness we see as follows. Suppose there is some ordered basis for \(V\) in which \(T\) is represented by some Jordan matrix \(A\) described in the previous paragraph. If \(A_i\) is a \(d_i \times d_i\) matrix, then we know 
\[
    \mathrm{ch}_A(x) = \mathrm{ch}_{A_1}(x) \dots \mathrm{ch}_{A_k}(x),   
\]     
and note that 
\[
    (A_i - c_i I )^{d_i} = 0
\] so \(x^{d_i} \mid \mathrm{m}_{A_i}(x) \mid \mathrm{ch}_{A_i}(x)  \), and since \(\deg \mathrm{ch}_{A_i}(x) = d_i \), so we know \(\mathrm{ch}_{A_i}(x) = (x - c_i)^{d_i} \), which gives 
\[
    \mathrm{ch}_A(x) = (x - c_1)^{d_1} \dots (x - c_k)^{d_k},  
\]  
so the characteristic polynomial is unique given a matrix in Jordan form. Hence, for a given linear operator \(T\) with \(\mathrm{ch}_T(x) = (x - c_1)^{d_1} \dots (x - c_k)^{d_k} \), we know its Jordan form must be the direct product of \(A_i\)'s where \(A_i\) has diagonal entries all \(c_i\) and the only place that may not be unique is the size of the Jordan blocks. Hence, if we can prove the following theorem, then we can show that the Jordan form of \(T\) is unique. 

\begin{theorem}
    If \(N\) is 
    \[
        J_{s_1}(0) \oplus J_{s_2}(0) \oplus \dots \oplus J_{s_r}(0),
    \] then \(\left\{ s_i \right\}_{i=1}^r \) is unique up to permutation. 
\end{theorem}
\begin{proof}
    Note that 
    \[
        \dim \ker N^k = \sum_{i=1}^r \dim \ker \left( J_i(0)^k \right)  
    \]
    by rank and nullity theorem. Also, since \(J_i(0)\) is nilpotent, so we can observe that 
    \[
        \dim \ker \left( J_i(0)^k \right) = \min \left\{ s_i, k \right\}  
    \] since \(J_i(0)\) is of the form 
    \[
        \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & 0  \\
    \end{pmatrix}
    \] and 
    \[
        \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & 0  \\
    \end{pmatrix} \cdot \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        0 & 1 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 1 & 0  \\
    \end{pmatrix} = \begin{pmatrix}
        0 & 0 & \cdots & 0 & 0  \\
        0 & 0 & \cdots & 0 & 0  \\
        1 & 0 & \cdots & 0 & 0  \\
        \vdots & \vdots & \ddots & \vdots & \vdots  \\
        0 & 0 & \cdots & 0 & 0  \\
    \end{pmatrix},
    \]
    which shift the \(1\)-line left by \(1\). Hence, 
    \[
        \dim \ker N^k = \sum_{i=1}^r \min \left\{ s_i, k \right\},  
    \] 
    and thus we have 
    \begin{align*}
        \dim \ker N^{k+1} - \dim \ker N^k &= \sum_{i=1}^r \min \left\{ s_i, k+1 \right\} - \min \left\{ s_i, k \right\} \\
        &= \# \text{ of Jordan blocks of size } \ge k+1 \\
        &= \ell _{k+1},    
    \end{align*} 
    so the number of Jordan blocks of size \(k\) is \(\ell _k - \ell _{k+1}\) and 
    \[
        \ell _k - \ell _{k+1} = \left( \dim \ker N^k - \dim \ker N^{k-1} \right) - \left( \dim \ker N^{k+1} - \dim \ker N^k \right),  
    \]  
    which is unique for any \(N\), so we know \(\left\{ s_i \right\}_{i=1}^k \) is unique.  
\end{proof}

\begin{remark}
    We say this theorem shows the uniqueness of Jordan form since
    \[
        A = A_1 \oplus \dots \oplus A_k,
    \]
    and \(A_i = N_i + c_i I\), so if we show \(N_i\) is unique, then \(A_i\) is unique.   
\end{remark}

\begin{corollary}
    Given any linear operator \(T\), then if \(\mathrm{ch}_T(x) \) splits, then \(T\) has a unique Jordan form.  
\end{corollary}

Now we with to make some further observations about the operator \(T\) and the Jordan matrix \(A\) which represents \(T\) in some ordered basis.

\begin{itemize}
    \item [(i)] Every characteristic value \(c_i\) of \(T\) is repeated \(d_i\) times on the diagonal line, where \(d_i\) is the multiplicity of \(c_i\) as a root of \(\mathrm{ch}_T(x) \), i.e. \(d_i = \dim W_i\). 
    \item [(ii)] For each \(i\), the matrix \(A_i\) is the direct sum of \(n_i\) Jordan blocks with characteristic value \(c_i\). For \(n_i\), the number of Jordan blocks in \(A_i\), we know it is equal to \(\dim \ker (T - c_i I)\). In particular, \(T\) is diagonalizable if and only if \(n_i = d_i\) for eeach \(i\). 
    \item [(iii)] For each \(i\), the size of the biggest Jordan block in \(A_i\) is \(r_i\), where \(r_i\) is the multiplicity of \(c_i\) as a root of \(m_T(x)\). This follows from the fact that the minimal polynomial for the nilpotent operator \((T_i - c_i I)\) is \(x^{r_i}\).                      
\end{itemize}