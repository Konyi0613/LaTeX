\begin{problem}
    Let \(V\) be a two-dimensional vector space over the field \(F\), and let \(\mathcal{B} \) be an ordered basis for \(V\), If \(T\) is a linear operator on \(V\) and 
    \[
        [T]_{\mathcal{B}} = \begin{bmatrix}
            a & b  \\
            c & d  \\
        \end{bmatrix},
    \] prove that \(T^2 - (a+d)T + (ad - cb)I = 0\). 
\end{problem}
\begin{proof}
    Note that 
    \[
        \left[ T^2 \right] _{\mathcal{B} } = [T]_{\mathcal{B} } [T]_{\mathcal{B} } = \begin{bmatrix}
            a & b  \\
            c & d  \\
        \end{bmatrix} \begin{bmatrix}
            a & b  \\
            c & d  \\
        \end{bmatrix} = \begin{bmatrix}
            a^2 + bc & ab + bd  \\
            ca + cd & bc + d^2  \\
        \end{bmatrix}.
    \]
    Hence, 
    \begin{align*}
        \left[ T^2 - (a + d)T + (ad - cb)I \right]_{\mathcal{B} } &= \left[ T^2 \right]_{\mathcal{B} } - (a+d)[T]_{\mathcal{B} } + (ad - cb)[I]_{\mathcal{B} } \\
        &= \begin{bmatrix}
            a^2 + bc & ab + bd  \\
            ca + cd & bc + d^2  \\
        \end{bmatrix} - (a + d) \begin{bmatrix}
            a & b  \\
            c & d  \\
        \end{bmatrix} + (ad - cb)\begin{bmatrix}
            1 & 0  \\
            0 & 1  \\
        \end{bmatrix} \\
         &= \begin{bmatrix}
            0 & 0  \\
            0 & 0  \\
         \end{bmatrix},
    \end{align*}
    which means \(T^2 - (a+d)T + (ad - cb)I = 0\). 
\end{proof}
\begin{problem}
    Let \(T\) be the linear operator on \(\mathbb{R}^2\) defined by
    \[
    T(x_1,x_2)=(-x_2,x_1).
    \]
    \begin{enumerate}[(a)]
        \item What is the matrix of \(T\) in the standard ordered basis for \(\mathbb{R}^2\)?
        \item What is the matrix of \(T\) in the ordered basis \(\mathcal{B}=\{\alpha_1,\alpha_2\}\), where \(\alpha_1=(1,2)\) and \(\alpha_2=(1,-1)\)?
        \item Prove that for every real number \(c\) the operator \((T-cI)\) is invertible.
        \item Prove that if \(\mathcal{B}\) is any ordered basis for \(\mathbb{R}^2\) and \([T]_{\mathcal{B}}=A\), then \(A_{12}A_{21}\neq 0\).
    \end{enumerate}
\end{problem}
\begin{proof}
    \vphantom{text}
    \begin{itemize}
        \item [(a)] Suppose the standard ordered basis is \(B = \left\{ e_1, e_2 \right\} \), then we know 
        \begin{align*}
            &T(1, 0) = (0, 1) = 0 \cdot e_1 + 1 \cdot e_2 \\
            &T(0, 1) = (-1, 0) = (-1) \cdot e_1 + 0 \cdot e_2.
        \end{align*}
        Hence, we know 
        \[
            [T]_B = \begin{bmatrix}
                0 & -1  \\
                1 & 0  \\
            \end{bmatrix}.
        \]
        \item [(b)] Since we have 
        \begin{align*}
            &T(\alpha _1) = (-2, 1) = -\frac{1}{3}\alpha _1 - \frac{5}{3}\alpha _2 \\
            &T(\alpha _2) = (1, 1) = \frac{2}{3}\alpha _1 + \frac{1}{3}\alpha _2,
        \end{align*}
        so we know 
        \[
            [T]_{\mathcal{B} } = \begin{bmatrix}
                -\frac{1}{3} & \frac{2}{3}  \vspace{0.8em}\\
                -\frac{5}{3} & \frac{1}{3}  \\
            \end{bmatrix}.
        \]
        \item [(c)] Suppose \(B\) is the standard ordered basis, then by (a) we know 
        \[
            [T]_B = \begin{bmatrix}
                0 & -1  \\
                1 & 0  \\
            \end{bmatrix}
        \] and thus for any real number \(c\) we have 
        \[
            [T - cI]_B = \begin{bmatrix}
                -c & -1  \\
                1 & -c  \\
            \end{bmatrix}.
        \] Note that for any \(c \in \mathbb{R} \) we must have \(\rank (T - cI) = \rank [T - cI]_B = 2\), which means \(T - cI\) is surjective and thus bijective, so \(T - cI\) is invertible.
        
        \item [(d)] Suppose \(\mathcal{B} = \left\{ (a, b), (c, d) \right\} \) is a basis of \(\mathbb{R} ^2\). If \(A_{12} = 0\), then since by definition we have 
        \begin{align*}
            &(-b, a) = A_{11} (a, b) + A_{21} (c, d) = \left( A_{11} a + A_{21}c, A_{11}b + A_{21}d  \right)  \\
            &(-d, c) = A_{12} (a, b) + A_{22} (c, d) = \left( A_{12}a + A_{22}c, A_{12}b + A_{22}d     \right),
        \end{align*} we have 
        \[
            (-d, c) = A_{22} (c, d), 
        \] and this gives \((1 +A_{22} )^2 c = 0\), which means \(c = 0\), and then this impiles \(d = 0\), but this means \((c, d) = (0, 0) \in \mathcal{B} \), which is a basis of \(\mathbb{R} ^2\), so it is a contradiction, and thus \(A_{12} \neq 0\). Similarly, we can get \(A_{21} \neq 0 \), and thus we have \(A_{12} A_{21} \neq 0  \).        
    \end{itemize}
\end{proof}
\begin{problem}
    Let \(\theta\) be a real number.  Prove that the following two matrices are similar over the field of complex numbers:
    \[
    \begin{bmatrix}
        \cos\theta & -\sin\theta \\[4pt]
        \sin\theta & \cos\theta
    \end{bmatrix},
    \qquad
    \begin{bmatrix}
        e^{i\theta} & 0 \\[4pt]
        0 & e^{-i\theta}
    \end{bmatrix}.
    \]
    (Hint: Let \(T\) be the linear operator on \(\mathbb{C}^2\) which is represented by the first matrix in the standard ordered basis. Then find vectors \(\alpha_1\) and \(\alpha_2\) such that \(T\alpha_1=e^{i\theta}\alpha_1\), \(T\alpha_2=e^{-i\theta}\alpha_2\), and \(\{\alpha_1,\alpha_2\}\) is a basis.)
\end{problem}
\begin{proof}
    First, we suppose the first matrix is the matrix of a linear operator \(T\) on standard basis of \(\mathbb{C} ^2\), then we know 
    \[
        T(ae_1 + be_2) = (a \cos \theta - b \sin \theta , a \sin \theta + b \cos \theta ).
    \] Now since \(e^{i \theta } = \cos \theta + i \sin \theta \), and if \(\alpha _1 = ae_1 + be_2\), then 
    \[
        T(a e_1 + b e_2) = (a \cos \theta - b \sin \theta , a \sin \theta + b \cos \theta ) = e^{i \theta }(ae_1 + b e_2) = ((\cos \theta + i \sin \theta )a, (\cos \theta + i \sin \theta )b).
    \]  This gives \(ai = -b\), so we can pick \(\alpha _1 = (1, -i)\), and use similar method, we can pick \(\alpha _2 = (1, i)\). Note that \(\left\{ (1, -i), (1, i) \right\} \) is a basis of \(\mathbb{C} ^2\) since if \(z_1, z_2 \in \mathbb{C} \) and \(z_1 (1, -i) + z_2 (1, i) = (0, 0)\), then 
    \[
        \begin{dcases}
            z_1 + z_2 = 0 \\
            i(-z_1 + z_2) = 0
        \end{dcases},
    \] which shows \(z_1 = z_2 = 0\), and thus \(\left\{ (1, -i), (1, i) \right\} \) is a linearly independent set with size \(2 = \dim \mathbb{C} ^2\), so it is a basis, and we're done.    
\end{proof}

\begin{problem}
    We have seen that the linear operator \(T\) on \(\mathbb{R}^2\) defined by \(T(x_1,x_2)=(x_1,0)\) is represented in the standard ordered basis by the matrix
    \[
    A=\begin{bmatrix}1 & 0 \\[4pt] 0 & 0 \end{bmatrix}.
    \]
    This operator satisfies \(T^2=T\).  Prove that if \(S\) is a linear operator on \(\mathbb{R}^2\) such that \(S^2=S\), then \(S=0\), or \(S=I\), or there is an ordered basis \(\mathcal{B}\) for \(\mathbb{R}^2\) such that \([S]_{\mathcal{B}}=A\) (above).
\end{problem}
\begin{proof}
    Since \(\dim \Im S \le 2\), so we can discuss all cases: 
    \begin{itemize}
        \item Case 1: \(\dim \Im S = 0\), then \(S = 0\). 
        \item Case 2: \(\dim \Im S = 1\). Note that for all \(w \in \Im S\), we have \(S(v) = w\) for some \(v \in \mathbb{R} ^2\), and thus \(w = S(v) = S^2(v) = S(w)\), so we have \(S(w) = w\). Now since we know \(\dim \ker S = 2 - \dim \Im S = 1\), so there exists \(v \in \ker S\) s.t. \(v \neq 0\), which means \(S(v) = 0\) with \(v \neq 0\), so \(v \notin \Im S\) since every \(w\) in \(\Im S\) has \(S(w) = w\). Hence, we can pick any \(u \in \Im S\), and then \(\left\{ v, u \right\} \) forms a basis of \(\mathbb{R} ^2\) since it is an linearly independent set of size \(2\). Suppose \(\mathcal{B}  = \left\{ u, v \right\} \), then 
        \[
            [S]_{\mathcal{B} } = \begin{bmatrix}
                1 & 0  \\
                0 & 0  \\
            \end{bmatrix}
        \] since \(S(u) = u = 1 \cdot u + 0 \cdot v\) and \(S(v) = 0 = 0 \cdot u + 0 \cdot v\).  
        \item Case 3: \(\dim \Im S = 2\), then \(S\) is bijective and thus \(S^{-1} \) exists, so 
        \[
            S = (S^2)\left( S^{-1}  \right) = S S ^{-1} = I,
        \]which shows \(S = I\). 
    \end{itemize} 
\end{proof}

\begin{problem}
    Let \(V\) be an \(n\)-dimensional vector space over the field \(F\), and let \(\mathcal{B}=\{\alpha_1,\dots,\alpha_n\}\) be an ordered basis for \(V\).
    \begin{itemize} 
        \item [(a)] According to Theorem 1, there is a unique linear operator \(T\) on \(V\) such that
        \[
            T\alpha_i=\alpha_{i+1},\quad j=1,\dots,n-1,\qquad T\alpha_n=0.
        \]
        What is the matrix \(A\) of \(T\) in the ordered basis \(\mathcal{B}\)?
        
        \item [(b)] Prove that \(T^n=0\) but \(T^{n-1}\neq 0\).
        
        \item [(c)] Let \(S\) be any linear operator on \(V\) such that \(S^n=0\) but \(S^{n-1}\neq 0\).  Prove that there is an ordered basis \(\mathcal{B}'\) for \(V\) such that the matrix of \(S\) in the ordered basis \(\mathcal{B}'\) is the matrix \(A\) of part (a).
        
        \item [(d)] Prove that if \(M\) and \(N\) are \(n\times n\) matrices over \(F\) such that \(M^n=N^n=0\) but \(M^{n-1}\neq 0\neq N^{n-1}\), then \(M\) and \(N\) are similar.
    \end{itemize}
\end{problem}
\begin{proof}
    \vphantom{text}
    \begin{itemize}
        \item [(a)] By definition, we know \(A = (a_{ij})_{n \times n}\) is 
        \[
            a_{ij} = \begin{dcases}
                1, &\text{ if }  i = j + 1;\\
                0, &\text{ otherwise}.
            \end{dcases}
        \]
        \item [(b)] For all \(\sum_{i=1}^n c_i \alpha _i \in V\), we have 
        \[
            T^n \left( \sum_{i=1}^n c_i \alpha _i  \right) = \sum_{i=1}^n c_i T^n(\alpha _i) = \sum_{i=1}^n c_i \cdot 0 = 0.  
        \]
        However, we have 
        \[
            T^{n-1} \left( \sum_{i=1}^n c_i \alpha _i  \right) = \sum_{i=1}^n c_i T^{n-1}(\alpha _i) = c_1 \alpha _n.  
        \]Hence, if we pick some vector with \(c_1 \neq 0\), then \(T^{n-1}\) will not map it to \(0\), and thus \(T^{n-1} \neq 0\). 
        \item [(c)] If we pick some \(v \in V\) with \(S^{n-1}(v) \neq 0\), then we claim that 
        \[
            \mathcal{B} ^{\prime} = \left\{ v, S(v), S^2(v), \dots , S^{n-1}(v) \right\} 
        \] is a basis of \(V\). Suppose \(\sum_{i=0}^{n-1} c_i S^{i}(v) = 0 \), then applying \(S\) on both sides, we will get 
        \[
            c_0 S(v) + c_1 S^2(v) + \dots + c_{n-2} S^{n-1}(v) = 0.
        \]Keep doing this, we will have \(c_0 S^{n-1}(v) \neq 0\). Now since \(S^{n-1}(v) \neq 0\), so \(c_0 = 0\), and go back to the last equation, which is 
        \[
            c_0 S^{n-2}(v) + c_1 S^{n-1}(v) = 0,
        \] we have \(c_1 = 0\), and keep going back, we will get \(c_i = 0\) for all \(0 \le i \le n - 1\), which means \(\mathcal{B} ^{\prime} \) is linearly independent, and since it is a set of size \(n = \dim V\), so \(\mathcal{B} ^{\prime} \) is a basis, and thus we know \([S]_{\mathcal{B} ^{\prime} }\) is the matrix \(A\) of part (a). 
        \item [(d)] By (c), \(M, N\) are both similar to the matrix \(A\) of part (a), so \(M, n\) are similar since "similar" is an equivalence relation.         
    \end{itemize}
\end{proof}