\begin{problem}
    Let \(W_1, W_2\) be subspaces of a finite dimensional vector space \(V\). 
    \begin{itemize}
        \item [(a)] Prove that \((W_1 + W_2)^0 = W_1^0 \cap W_2^0\). 
        \item [(b)] Prove that \(\left( W_1 \cap W_2 \right)^0 = W_1^0 + W_2^0 \). 
    \end{itemize}  
\end{problem}
\begin{proof}
    \vphantom{text}
    \begin{itemize}
        \item [(a)] If \(f \in (W_1 + W_2)^0\), then \(f(w_1 + w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\). Now since \(0 \in W_1\) and \(0 \in W_2\), so we can pick \(w_2 = 0\) so obtain \(f(w_1) = 0\) for all \(w_1 \in W_1\) and similarly we can obtain \(f(w_2) = 0\) for all \(w_2 \in W_2\). Hence, \(f \in W_1^0 \cap W_2^0\). This means \((W_1 + W_2)^0 \subseteq W_1^0 \cap W_2^0\). Now if \(g \in W_1^0 \cap W_2^0\), then since \(g(w_1) = 0\) and \(g(w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\), so we know \(g(w_1 + w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\), and this means \(g(w) = 0\) for all \(w \in W_1 + W_2\). Hence, \(g \in (W_1 + W_2)^0\), which gives \(W_1^0 \cap W_2^0 \subseteq (W_1 + W_2)^0\). Hence, \((W_1 + W_2)^0 = W_1^0 \cap W_2^0\).                       
        \item [(b)] We first claim that \(\dim (W_1 \cap W_2)^0 = \dim \left( W_1^0 + W_2^0 \right) \):
        \begin{align*}
            \dim \left( W_1 \cap W_2 \right)^0 &= \dim V - \dim (W_1 \cap W_2) \\
            \dim \left( W_1^0 + W_2^0 \right) &= \dim W_1^0 + \dim W_2^0 - \dim \left( W_1^0 \cap W_2^0 \right) \\
            &= \left( \dim V - \dim W_1 \right) + \left( \dim V - \dim W_2 \right) - \dim \left( W_1 + W_2 \right)^0 \quad \text{(by (a))} \\
            &= 2 \dim V - \dim W_1 - \dim W_2 - \left( \dim V - \dim (W_1 + W_2) \right) \\
            &= \dim V + \dim (W_1 + W_2) - \dim W_1 - \dim W_2 \\
            &= \dim V - \dim (W_1 \cap W_2). 
        \end{align*}
        Hence, we've prove it. Now we prove that \(W_1^0 + W_2^0 \subseteq \left( W_1 \cap W_2 \right)^0 \). If \(f \in W_1^0 + W_2^0\), then \(f = g + h\) for some \(g \in W_1^0\) and \(h \in W_2^0\). Hence, we know for all \(w \in W_1 \cap W_2\), \(f(w) = g(w) + h(w) = 0\), which means \(f \in \left( W_1 \cap W_2 \right)^0 \), so \(W_1^0 + W_2^0 \subseteq (W_1 \cap W_2)^0\). 
        
        Now since we know 
        \[
            \begin{dcases}
                \dim \left( W_1 \cap W_2 \right)^0 = \dim \left( W_1^0 + W_2^0 \right) \\
                W_1^0 + W_2^0 \subseteq \left( W_1 \cap W_2 \right)^0,   
            \end{dcases}
        \]so we know \(\left( W_1 \cap W_2 \right)^0 = W_1^0 + W_2^0 \). 
    \end{itemize}
\end{proof}

\begin{problem}
    Let \(V\) be a finite-dimensional vector space over the field \(F\) and let \(W\) be a subspace of \(V\). If \(f\) is a linear functional on \(W\), prove that there is a linear functional \(g\) on \(V\) such that \(g(\alpha ) = f(\alpha )\) for each \(\alpha \) in the subspace \(W\).           
\end{problem}
\begin{proof}
    Suppose \(B = \left\{ w_1, \dots , w_n \right\} \) is a basis of \(W\), and extend it to 
    \[
        C = \left\{ w_1, \dots , w_n, v_{n+1}, \dots , v_m \right\}, 
    \] and makes \(C\) a basis of \(V\), then if we take dual of \(C\), say 
    \[
        C^* = \left\{ w_1^*, \dots , w_n^*, v_{n+1}^*, \dots , v_m^* \right\}, 
    \] then we know \(f = \sum_{i=1}^n \alpha _i w_i^* \) for some \(\alpha _i\)'s in \(F\) since 
    \[
        \left\{ w_1^*, w_2^*, \dots , w_n^* \right\} 
    \] is a basis \(W^*\) and \(f \in W^*\), and thus if we pick \(g = \sum_{i=1}^n \alpha _i w_i^* + \sum_{i=n+1}^m v_i^*   \), then since we know for all \(w \in W\), \(v_j^*(w) = 0\) for all \(n + 1 \le j \le m\), so 
    \[
        g(w) = \sum_{i=1}^n \alpha _i w_i^*(w) = f(w). 
    \]      
\end{proof}

\begin{problem}
    Let $S$ be a set, $F$ a field, and $V(S; F)$ the space of all functions from $S$ into $F$:
\begin{align*}
(f+g)(x) &= f(x) + g(x) \\
(cf)(x) &= c f(x).
\end{align*}
Let $W$ be any $n$-dimensional subspace of $V(S; F)$. Show that there exist points $x_1, \dots, x_n$ in $S$ and functions $f_1, \dots, f_n$ in $W$ such that $f_i(x_j) = \delta_{ij}$.
\end{problem}
\begin{proof}
    Suppose \(B = \left\{ g_1, g_2, \dots , g_n \right\} \) is a basis of \(W\), then we define 
    \[
        L_x: W \to F, \quad L_x(g) = g(x)
    \] where \(x \in S\). 
    \begin{claim}
        \(\exists x_1, x_2, \dots ,x_n \in S\) s.t. \(\mathcal{L} = \left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly independent in \(W^*\).   
    \end{claim}
    \begin{explanation}
        Suppose by contradiction, for all \(x_1, x_2, \dots , x_n\), \(\left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly dependent, then we know
        \[
            \dim \left( \Span \left\{ L_x: x\in S \right\}  \right) < n, 
        \] otherwise, we can pick \(\left\{ \sum_{x \in S} \alpha _{ji} L_{x}  \right\}_{j=1}^n \) s.t. this set is linearly independent, but notice that 
        \[
            \sum_{x \in S} \alpha _{ji} L_{x} = L_{\sum_{x \in S} \alpha _{ji} x } 
        \] by the definition of \(L_x\), and this means we can pick \(n\) points \(\left\{ y_j = \sum_{x \in S} \alpha _{ji} x  \right\}_{j=1}^n \) s.t. \(\left\{ L_{y_j} \right\}_{j=1}^n \) is linearly independent, which is a contradiction. 
        
        Now since \(\dim \left( \Span \left\{ L_x: x \in S \right\}  \right) < n \), and \(\dim W^* = \dim W = n\), so we know 
        \[
            \dim \left( \Span \left\{ L_x : x \in S \right\}  \right)^0 = \dim W^* - \dim \left( \Span \left\{ L_x: x \in S \right\}  \right) \ge 1, 
        \] so we can pick \(T \neq 0\) s.t. \(T \in \left( \Span \left\{ L_x: x \in S \right\}  \right)^0 \). Now since we know 
        \[
            \mathcal{J} : W \to W^{* *}, \quad \mathcal{J} (w) (\varphi ) = \varphi (w) \quad \varphi \in W^*
        \] is an isomorphism, so we know there exists \(w \in W\) s.t. \(\mathcal{J} (w) = T\), and since \(T \neq 0\), so \(w \neq 0\). Also, since \(T \in \left( \Span \left\{ L_x : x \in S \right\}  \right)^0 \), so for all \(x \in S\) we have 
        \[
            0 = T(L_x) = \mathcal{J} (w) (L_x) = L_x(w) = w(x),
        \] which means \(w\) is the zero function in \(W\), which is a contradiction. Hence, there must exists \(x_1, x_2, \dots , x_n \in S\) s.t. \(\left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly independent. 
    \end{explanation} 
    By the claim above, we can pick \(\mathcal{L} = \left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) s.t. \(\mathcal{L} \) is linearly independent. Now suppose 
    \[
        A = \begin{pmatrix}
            L_{x_1}(g_1) & L_{x_1}(g_2) &  \cdots & L_{x_1}(g_n)  \\
            L_{x_2}(g_1) & L_{x_2}(g_2) & \cdots & L_{x_2}(g_n)  \\
            \vdots & \vdots & \ddots & \vdots  \\
            L_{x_n}(g_1) & L_{x_n}(g_2) & \cdots & L_{x_n}(g_n)  \\
        \end{pmatrix},
    \] and we will show that \(A\) is invertible. Suppose 
    \[
        v_i = \left( L_{x_i}(g_1), L_{x_i}(g_2), \dots , L_{x_i}(g_n) \right) = \left( g_1(x_i), g_2(x_i), \dots, g_n(x_i)  \right),  \quad \forall 1 \le i \le n, 
    \] and suppose \(\sum_{i=1}^n v_i = 0 \), then we have 
    \[
        \alpha _1 g_i(x_1) + \alpha _2 g_i (x_2) + \dots + \alpha _n g_i(x_n) = 0 \quad \forall 1 \le i \le n.
    \] 
    However, since we know \(\mathcal{L} \) is linearly independent, so 
    \begin{align*}
        \beta _1, \beta _2, \dots , \beta _n = 0 &\iff \beta _1 L_{x_1} + \beta _2 L_{x_2} + \dots + \beta _n L_{x_n} = 0 \\
        &\iff \beta _1 p(x_1) + \beta _2 p(x_2) + \dots + \beta _n p(x_n) = 0 \quad \forall p \in W \\
        &\iff \beta _1 g_i(x_1) + \beta _2 g_i(x_2) + \dots + \beta _n g_i(x_n) = 0 \quad \forall 1 \le i \le n.
    \end{align*} 
    Hence, we know \(\alpha _1 = \alpha _2 = \dots = \alpha _n = 0\), and thus \(\left\{ v_1, v_2, \dots , v_n \right\} \) is linearly independent, which shows all rows of \(A\) is linearly independent, so \(A\) is invertible.
    
    Now since \(A\) is invertible, so we can do row operations to make \(A\) becomes \(I_n\), and suppose 
    \[
        I_n = A^{\prime} = E_1 E_2 \dots E_k A, 
    \] where \(E_1, E_2, \dots , E_k\) are some elementary matrices, then if \(A^{\prime} = \left( a_{ij}^{\prime}  \right)_{n \times n} \), then 
    \[
        a _{ij}^{\prime} = \sum_{k=1}^n \beta _{ki} L_{x_k} (g_j) \quad \text{for some constants } \beta _{ki}\text{'s } \forall 1 \le i \le n.
    \] Hence, we know 
    \[
        a_{ij}^{\prime} = L_{\sum_{k=1}^n \beta _{ki} x_k } (g_j),
    \] and since \(A^{\prime} = I_n\), so \(a_{ij}^{\prime} = \delta _{ij}\), which means if we pick \(y_i = \sum_{k=1}^n \beta _{ki}x_k \) and then we have
    \[
        g_i(y_j) = \delta _{ij}. 
    \]
\end{proof}

\begin{problem}
Let $n$ be a positive integer and let $V$ be the space of all polynomial functions over the field of real numbers which have degree at most $n$, i.e., functions of the form
\[
f(x) = c_0 + c_1 x + \cdots + c_n x^n.
\]
Let $D$ be the differentiation operator on $V$. Find a basis for the null space of the transpose operator $D^{t}$.
\end{problem}
\begin{proof}
    Suppose \(B=\left\{ 1, x, x^2, \dots , x^n \right\} \), then we know \(B\) is a basis of \(V\), and suppose \(B^* = \left\{ f_0, f_1, \dots , f_n \right\} \) is the dual basis of \(B\), then since 
    \[
        \left[ D^t \right]_{B^*}^{B^*} = \left( [D]_B^B \right)^t, 
    \] so we can first find out \([D]_B^B\). Note that 
    \begin{align*}
        D(1) &= 0 = 0 \cdot 1 + 0 \cdot x + \dots + 0 \cdot x^n \\
        D(x) &= 1 = 1 \cdot 1 + 0 \cdot x + \dots + 0 \cdot x^n \\
        D\left( x^2 \right) &= 2x = 0 \cdot 1 + 2 \cdot x + \dots + 0 \cdot x^n \\
        &\vdots \\
        D \left( x^n \right) &= n x^{n-1} = 0 \cdot 1 + 0 \cdot x + \dots + n x^{n-1} + 0 \cdot x^n.
    \end{align*} 
    Hence, 
    \[
        [D]_B^B = \begin{pmatrix}
            0 & 1 & 0 & \cdots & 0  \\
            0 & 0 & 2 & \cdots & 0  \\
            \vdots & \vdots & \vdots & \cdots & \vdots  \\
            0 & 0 & 0 & \ddots & n  \\
            0 & 0 & 0 & \cdots & 0  \\
        \end{pmatrix},
    \] and thus 
    \[
        \left[ D^t \right]_{B^*}^{B^*} = \left( [D]_B^B \right)^t =
        \begin{pmatrix}
            0 & 0 & \cdots & 0 & 0  \\
            1 & 0 & \cdots & 0 & 0  \\
            0 & 2 & \cdots & 0 & 0 \\
            \vdots & \vdots & \vdots & \ddots & \vdots  \\
            0 & 0 & \cdots & n & 0  \\
        \end{pmatrix},
    \] and if \(v = (a_0, a_1, \dots , a_n)^t \in \ker \left[ D^t \right]_{B^*}^{B^*} \), then we know \(\left[ D^t \right]_{B^*}^{B^*}v = 0\), which gives 
    \begin{align*}
        1 &\cdot a_0 = 0 \\
        2 &\cdot a_1 = 0 \\
        &\vdots \\
        n &\cdot a_{n-1} = 0.
    \end{align*} 
    Hence, we know \(v = (0, 0, \dots , 0, a_n)\). Thus, 
    \[
        \ker D^t = \Span \left\{ f_n \right\}, 
    \] where 
    \[
        f_n \left( b_n x^n + b_{n-1} x^{n-1} + \dots + b_1 x + b_0 \right) = b_n \quad \forall b_n x^n + b_{n-1} x^{n-1} + \dots + b_1 x + b_0 \in V. 
    \]
\end{proof}

\begin{problem}
    Let \(V\) be the vector space of \(n \times n\) matrices over the field \(F\). 
    \begin{itemize}
        \item [(a)] If \(B\) is a fixed \(n \times n\) matrix, define a function \(f_B\) on \(V\) by \(f_B(A) = \Tr \left( B^t A \right) \). Show that \(f_B\) is a linear functional on \(V\).       
        \item [(b)] Show that every linear functional \(f\) on \(V\) is of the above form, i.e., is \(f_B\) for some \(B\).     
        \item [(c)] Show that \(B \to f_B\) is an isomorphism of \(V\) onto \(V^*\).   
    \end{itemize} 
\end{problem}
\begin{proof}
    \vphantom{text}
    \begin{itemize}
        \item [(a)] Since we know \(f_B: V \to F\), so we just need to show that \(f_B\) is linear. Suppose \(P, Q \in V\) and \(\alpha \in F\), then 
        \begin{align*}
            f_B \left( \alpha P + Q \right) &= \Tr \left( B^t (\alpha P + Q) \right) \\
            &= \Tr \left( B^t (\alpha P) + B^t Q\right) \\
            &= \Tr \left( B^t (\alpha P) \right) + \Tr \left( B^t Q \right) \\
            &= \alpha \Tr \left( B^t P \right)  + \Tr \left( B^t Q \right) \\
            &= \alpha f_B(P) + f_B(Q),
        \end{align*}    
        so we know \(f_B\) is linear, and we're done. 
        \item [(b)] Suppose \(E = \left\{ e_{ij} \right\}_{1 \le i, j \le n} \) is the standard basis of \(V\), then if we take dual basis of \(E\), say it is \(E^* = \left\{ e^*_{ij} \right\}_{1 \le i, j \le n} \), then if \(X = (x_{ij})_{n \times n}\), we have \(e^*_{ij}(X) = x_{ij}\). Now if \(f \in V^*\), then we know 
        \[
            f = \sum_{1 \le i, j \le n} \beta _{ij} e_{ij}^* 
        \] for some constants \(\beta _{ij}\)'s. Hence, we know for all \(X = (x_{ij})_{n \times n}\), we have 
        \[
            f(X) = \sum_{1 \le i, j \le n} \beta _{ij} x_{ij} = \Tr \left( \begin{pmatrix}
                \beta _{11} & \beta _{21} & \cdots & \beta _{n1}  \\
                \beta _{12} & \beta _{22} & \cdots & \beta _{n2}  \\
                \vdots & \vdots &\ddots  & \vdots  \\
                \beta _{1n} & \beta _{2n} & \cdots & \beta _{nn}  \\
            \end{pmatrix} \begin{pmatrix}
                x_{11}  & x_{12}  & \cdots & x_{1n}  \\
                x_{21} & x_{22} & \cdots & x_{2n}  \\
                \vdots & \vdots & \ddots & \vdots  \\
                x_{n1} & x_{n2} & \cdots & x_{nn}  \\
            \end{pmatrix} \right) = \Tr (B^t X),
        \] where 
        \[
            B = \begin{pmatrix}
                    \beta_{11} & \beta_{12} & \cdots & \beta_{1n} \\
                    \beta_{21} & \beta_{22} & \cdots & \beta_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \beta_{n1} & \beta_{n2} & \cdots & \beta_{nn}
                \end{pmatrix}.
        \]
        \item [(c)] Suppose \(T\) is the map sending \(B\) to \(f_B\), then we want to show that \(T\) is an isomorphism. We first show that \(T\) is linear. Suppose \(A, B \in V\) and \(\alpha \in F\), then for all \(X \in V\), we have 
        \begin{align*}
            T \left( \alpha A + B \right)(X) &= f_{\alpha A + B}(X) \\
            &= \Tr \left( (\alpha A + B)^t X \right) \\
            &= \Tr \left( \alpha A^t X + B^t X \right) \\
            &= \alpha \Tr \left( A^tX \right) + \Tr \left( B^t X \right) \\
            &= \alpha f_A (X) + f_B(X) = (\alpha T(A) + T(B))(X), 
        \end{align*}
        so \(T\) is linear. Now we show that \(T\) is bijective. Since \(\dim V = \dim V^*\), so we just need to show that \(T\) is surjective. By (b), we know for all \(f \in V^*\), \(f = f_B = T(B)\) for some \(B \in V\), so \(T\) is surjective, and we're done.       
    \end{itemize}
\end{proof}