\begin{problem}
    Let \(W_1, W_2\) be subspaces of a finite dimensional vector space \(V\). 
    \begin{itemize}
        \item [(a)] Prove that \((W_1 + W_2)^0 = W_1^0 \cap W_2^0\). 
        \item [(b)] Prove that \(\left( W_1 \cap W_2 \right)^0 = W_1^0 + W_2^0 \). 
    \end{itemize}  
\end{problem}
\begin{proof}
    \vphantom{text}
    \begin{itemize}
        \item [(a)] If \(f \in (W_1 + W_2)^0\), then \(f(w_1 + w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\). Now since \(0 \in W_1\) and \(0 \in W_2\), so we can pick \(w_2 = 0\) so obtain \(f(w_1) = 0\) for all \(w_1 \in W_1\) and similarly we can obtain \(f(w_2) = 0\) for all \(w_2 \in W_2\). Hence, \(f \in W_1^0 \cap W_2^0\). This means \((W_1 + W_2)^0 \subseteq W_1^0 \cap W_2^0\). Now if \(g \in W_1^0 \cap W_2^0\), then since \(g(w_1) = 0\) and \(g(w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\), so we know \(g(w_1 + w_2) = 0\) for all \(w_1 \in W_1\) and \(w_2 \in W_2\), and this means \(g(w) = 0\) for all \(w \in W_1 + W_2\). Hence, \(g \in (W_1 + W_2)^0\), which gives \(W_1^0 \cap W_2^0 \subseteq (W_1 + W_2)^0\). Hence, \((W_1 + W_2)^0 = W_1^0 \cap W_2^0\).                       
        \item [(b)] We first claim that \(\dim (W_1 \cap W_2)^0 = \dim \left( W_1^0 + W_2^0 \right) \):
        \begin{align*}
            \dim \left( W_1 \cap W_2 \right)^0 &= \dim V - \dim (W_1 \cap W_2) \\
            \dim \left( W_1^0 + W_2^0 \right) &= \dim W_1^0 + \dim W_2^0 - \dim \left( W_1^0 \cap W_2^0 \right) \\
            &= \left( \dim V - \dim W_1 \right) + \left( \dim V - \dim W_2 \right) - \dim \left( W_1 + W_2 \right)^0 \quad \text{(by (a))} \\
            &= 2 \dim V - \dim W_1 - \dim W_2 - \left( \dim V - \dim (W_1 + W_2) \right) \\
            &= \dim V + \dim (W_1 + W_2) - \dim W_1 - \dim W_2 \\
            &= \dim V - \dim (W_1 \cap W_2). 
        \end{align*}
        Hence, we've prove it. Now we prove that \(W_1^0 + W_2^0 \subseteq \left( W_1 \cap W_2 \right)^0 \). If \(f \in W_1^0 + W_2^0\), then \(f = g + h\) for some \(g \in W_1^0\) and \(h \in W_2^0\). Hence, we know for all \(w \in W_1 \cap W_2\), \(f(w) = g(w) + h(w) = 0\), which means \(f \in \left( W_1 \cap W_2 \right)^0 \), so \(W_1^0 + W_2^0 \subseteq (W_1 \cap W_2)^0\). 
        
        Now since we know 
        \[
            \begin{dcases}
                \dim \left( W_1 \cap W_2 \right)^0 = \dim \left( W_1^0 + W_2^0 \right) \\
                W_1^0 + W_2^0 \subseteq \left( W_1 \cap W_2 \right)^0,   
            \end{dcases}
        \]so we know \(\left( W_1 \cap W_2 \right)^0 = W_1^0 + W_2^0 \). 
    \end{itemize}
\end{proof}

\begin{problem}
    Let \(V\) be a finite-dimensional vector space over the field \(F\) and let \(W\) be a subspace of \(V\). If \(f\) is a linear functional on \(W\), prove that there is a linear functional \(g\) on \(V\) such that \(g(\alpha ) = f(\alpha )\) for each \(\alpha \) in the subspace \(W\).           
\end{problem}
\begin{proof}
    Suppose \(B = \left\{ w_1, \dots , w_n \right\} \) is a basis of \(W\), and extend it to 
    \[
        C = \left\{ w_1, \dots , w_n, v_{n+1}, \dots , v_m \right\}, 
    \] and makes \(C\) a basis of \(V\), then if we take dual of \(C\), say 
    \[
        C^* = \left\{ w_1^*, \dots , w_n^*, v_{n+1}^*, \dots , v_m^* \right\}, 
    \] then we know \(f = \sum_{i=1}^n \alpha _i w_i^* \) for some \(\alpha _i\)'s in \(F\) since 
    \[
        \left\{ w_1^*, w_2^*, \dots , w_n^* \right\} 
    \] is a basis \(W^*\) and \(f \in W^*\), and thus if we pick \(g = \sum_{i=1}^n \alpha _i w_i^* + \sum_{i=n+1}^m v_i^*   \), then since we know for all \(w \in W\), \(v_j^*(w) = 0\) for all \(n + 1 \le j \le m\), so 
    \[
        g(w) = \sum_{i=1}^n \alpha _i w_i^*(w) = f(w). 
    \]      
\end{proof}

\begin{problem}
    Let $S$ be a set, $F$ a field, and $V(S; F)$ the space of all functions from $S$ into $F$:
\begin{align*}
(f+g)(x) &= f(x) + g(x) \\
(cf)(x) &= c f(x).
\end{align*}
Let $W$ be any $n$-dimensional subspace of $V(S; F)$. Show that there exist points $x_1, \dots, x_n$ in $S$ and functions $f_1, \dots, f_n$ in $W$ such that $f_i(x_j) = \delta_{ij}$.
\end{problem}
\begin{proof}
    Suppose \(B = \left\{ g_1, g_2, \dots , g_n \right\} \) is a basis of \(W\), then we define 
    \[
        L_x: W \to F, \quad L_x(g) = g(x)
    \] where \(x \in S\). 
    \begin{claim}
        \(\exists x_1, x_2, \dots ,x_n \in S\) s.t. \(\mathcal{L} = \left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly independent in \(W^*\).   
    \end{claim}
    \begin{explanation}
        Suppose by contradiction, for all \(x_1, x_2, \dots , x_n\), \(\left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly dependent, then we know
        \[
            \dim \left( \Span \left\{ L_x: x\in S \right\}  \right) < n, 
        \] otherwise, we can pick \(\left\{ \sum_{x \in S} \alpha _{ji} L_{x}  \right\}_{j=1}^n \) s.t. this set is linearly independent, but notice that 
        \[
            \sum_{x \in S} \alpha _{ji} L_{x} = L_{\sum_{x \in S} \alpha _{ji} x } 
        \] by the definition of \(L_x\), and this means we can pick \(n\) points \(\left\{ y_j = \sum_{x \in S} \alpha _{ji} x  \right\}_{j=1}^n \) s.t. \(\left\{ L_{y_j} \right\}_{j=1}^n \) is linearly independent, which is a contradiction. 
        
        Now since \(\dim \left( \Span \left\{ L_x: x \in S \right\}  \right) < n \), and \(\dim W^* = \dim W = n\), so we know 
        \[
            \dim \left( \Span \left\{ L_x : x \in S \right\}  \right)^0 = \dim W^* - \dim \left( \Span \left\{ L_x: x \in S \right\}  \right) \ge 1, 
        \] so we can pick \(T \neq 0\) s.t. \(T \in \left( \Span \left\{ L_x: x \in S \right\}  \right)^0 \). Now since we know 
        \[
            \mathcal{J} : W \to W^{* *}, \quad \mathcal{J} (w) (\varphi ) = \varphi (w) \quad \varphi \in W^*
        \] is an isomorphism, so we know there exists \(w \in W\) s.t. \(\mathcal{J} (w) = T\), and since \(T \neq 0\), so \(w \neq 0\). Also, since \(T \in \left( \Span \left\{ L_x : x \in S \right\}  \right)^0 \), so for all \(x \in S\) we have 
        \[
            0 = T(L_x) = J(w) (L_x) = L_x(w) = w(x),
        \] which means \(w\) is the zero function in \(W\), which is a contradiction. Hence, there must exists \(x_1, x_2, \dots , x_n \in S\) s.t. \(\left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) is linearly independent. 
    \end{explanation} 
    By the claim above, we can pick \(\mathcal{L} = \left\{ L_{x_1}, L_{x_2}, \dots , L_{x_n} \right\} \) s.t. \(\mathcal{L} \) is linearly independent. Now suppose 
    \[
        A = \begin{pmatrix}
            L_{x_1}(g_1) & L_{x_1}(g_2) &  \cdots & L_{x_1}(g_n)  \\
            L_{x_2}(g_1) & L_{x_2}(g_2) & \cdots & L_{x_2}(g_n)  \\
            \vdots & \vdots & \ddots & \vdots  \\
            L_{x_n}(g_1) & L_{x_n}(g_2) & \cdots & L_{x_n}(g_n)  \\
        \end{pmatrix},
    \] and we will show that \(A\) is invertible. Suppose 
    \[
        v_i = \left( L_{x_i}(g_1), L_{x_i}(g_2), \dots , L_{x_i}(g_n) \right) = \left( g_1(x_i), g_2(x_i), \dots, g_n(x_i)  \right),  \quad \forall 1 \le i \le n, 
    \] and suppose \(\sum_{i=1}^n v_i = 0 \), then we have 
    \[
        \alpha _1 g_i(x_1) + \alpha _2 g_i (x_2) + \dots + \alpha _n g_i(x_n) = 0 \quad \forall 1 \le i \le n.
    \] 
    However, since we know \(\mathcal{L} \) is linearly independent, so 
    \begin{align*}
        \beta _1, \beta _2, \dots , \beta _n = 0 &\iff \beta _1 L_{x_1} + \beta _2 L_{x_2} + \dots + \beta _n L_{x_n} = 0 \\
        &\iff \beta _1 p(x_1) + \beta _2 p(x_2) + \dots + \beta _n p(x_n) = 0 \quad \forall p \in W \\
        &\iff \beta _1 g_i(x_1) + \beta _2 g_i(x_2) + \dots + \beta _n g_i(x_n) = 0 \quad \forall 1 \le i \le n.
    \end{align*} 
    Hence, we know \(\alpha _1 = \alpha _2 = \dots = \alpha _n = 0\), and thus \(\left\{ v_1, v_2, \dots , v_n \right\} \) is linearly independent, which shows all rows of \(A\) is linearly independent, so \(A\) is invertible.
    
    Now since \(A\) is invertible, so we can do row operations to make \(A\) becomes \(I_n\), and suppose 
    \[
        I_n = A^{\prime} = E_1 E_2 \dots E_k A, 
    \] where \(E_1, E_2, \dots , E_k\) are some elementary matrices, then if \(A^{\prime} = \left( a_{ij}^{\prime}  \right)_{n \times n} \), then 
    \[
        a _{ij}^{\prime} = \sum_{k=1}^n \beta _{ki} L_{x_k} (g_j) \quad \text{for some constants } \beta _{ki}\text{'s } \forall 1 \le i \le n.
    \] Hence, we know 
    \[
        a_{ij}^{\prime} = L_{\sum_{k=1}^n \beta _{ki} x_k } (g_j),
    \] and since \(A^{\prime} = I_n\), so \(a_{ij}^{\prime} = \delta _{ij}\), which means if we pick \(y_i = \sum_{k=1}^n \beta _{ki}x_k \) and then we have
    \[
        g_i(y_j) = \delta _{ij}. 
    \]
\end{proof}