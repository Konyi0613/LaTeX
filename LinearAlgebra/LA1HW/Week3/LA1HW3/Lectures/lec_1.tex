\section*{Sec 3.2}

\begin{problem*}
    Let \(T\) be a linear transformation from \(\mathbb{R}^3\) into \(\mathbb{R}^2\), and let \(U\) be a linear transformation from \(\mathbb{R}^2\) into \(\mathbb{R}^3\). Prove that the transformation \(UT\) is not invertible. Generalize the theorem.
\end{problem*}
\begin{proof}
    Since by rank and nullity theorem, we know 
    \[
        3 = \nu(T) + \rank(T),
    \] and \(\rank T \le 2\), so \(\nu (T) \ge 1\), which means \(T\) is not injective. Hence, there exists \(a \neq b\) s.t. \(T(a) = T(b)\), and thus \(UT(a) = UT(b)\), which means \(UT\) is not injective. Hence, \(UT\) is not invertible. To generalize the theorem, we can say if \(m > n\), and suppose \(T: V \to W\) and \(U: W \to U\) s.t. \(\dim V = \dim U = m\) and \(\dim W = n\), then \(UT\) is not invertible.       
\end{proof}

\begin{problem*}
Find two linear operators \(T\) and \(U\) on \(\mathbb{R}^2\) such that \(TU = 0\) but \(UT \neq 0\).
\end{problem*}
\begin{proof}
    Suppose 
    \[
        U(x, y) = (x + y, 2x + 2y) \quad T(x, y) = (y - 2x, 0),
    \] which are two linear operators on \(\mathbb{R} ^2\), then we know
    \[
        TU(x, y) = (0, 0) \quad UT(x, y) = (y - 2x, 2y - 4x).
    \]
\end{proof}
\begin{problem*}
Let \(V\) be a vector space over the field \(F\) and \(T\) a linear operator on \(V\). If \(T^2 = 0\), what can you say about the relation of the range of \(T\) to the null space of \(T\)? Give an example of a linear operator \(T'\) on \(\mathbb{R}^2\) such that \(T'^2 = 0\) but \(T' \neq 0\).
\end{problem*}
\begin{proof}
    If \(T^2 = 0\), then \(\Im T \subseteq \ker T\). Consider \(T^{\prime} (x, y) = (x + y, -x - y)\), then
    \[
        T^{\prime2}(x, y) = T^{\prime} (x + y, -x - y) = (0, 0) \quad \forall (x, y) \in \mathbb{R} ^2.
    \]   
\end{proof}
\begin{problem*}
Let \(T\) be a linear operator on the finite-dimensional space \(V\). Suppose there is a linear operator \(U\) on \(V\) such that \(TU = I\). Prove that \(T\) is invertible and \(U = T^{-1}\). Give an example which shows that this is false when \(V\) is not finite-dimensional. (Hint: Let \(T = D\), the differentiation operator on the space of polynomial functions.)
\end{problem*}
\begin{proof}
    Since for all \(a \in V\), we have \(T(U(a)) = a\), so \(T\) is surjective, and thus 
    \[
        \nu (T) + \rank (T) = \dim V 
    \]  gives \(\nu T = \dim V - \rank T = \dim V - \dim V = 0\), whcih means \(T\) is injective, so \(T\) is bijective and thus invertible. Now we claim \(U = T^{-1} \), that is, the inverse is unique. Suppose not, then there exists \(b \in V\) s.t. \(U(b) \neq T^{-1}(b)\), so we have 
    \[
        T(U(b)) = b = T(T^{-1}(b)),
    \] but this implies \(T\) is not injective, which is a contradiction. Now if \(T:\mathbb{R} \to \mathbb{R} \) is a linear operator with \(T(f) = D(f)\), where \(D(f)\) means differentiating \(f\), then in this case \(V = \mathbb{R} [x]\), which is not finite dimensional. Note that we can pick \(U:\mathbb{R} [x] \to \mathbb{R} [x]\) by \(U(f) = \int f \, \mathrm{d}x \), which is the anti-derivative of \(f\) with constant term equal \(0\), then we know \(TU = I\). However, \(T(x + 1) = T(x) = 1\), so \(T\) is not injective and thus cannot be invertible. Also, notice that there are infinitely many \(U^{\prime} \) s.t. \(TU^{\prime}  = I\) since we can let \(U^{\prime} = U + C\) for any constant \(C\). Hence, this statement is not true for infinite-dimensional \(V\).             
\end{proof}

\section*{Sec 3.3}

\begin{problem*}
Let \(W\) be the set of all \(2\times 2\) complex Hermitian matrices, that is, the set of \(2\times 2\) complex matrices \(A\) such that \(A_{ij}=\overline{A_{ji}}\) (the bar denoting complex conjugation). As we pointed out in Example 6 of Chapter 2, \(W\) is a vector space over the field of real numbers, under the usual operations. Verify that the map
\[
(x,y,z,t)\longmapsto
\begin{bmatrix}
t+x & y + i z\\[4pt]
y - i z & t - x
\end{bmatrix}
\]
is an isomorphism of \(\mathbb{R}^4\) onto \(W\).
\end{problem*}
\begin{proof}
    We first show this map is linear. Suppose this map is called \(T\), then we know for all \(\alpha \in \mathbb{R} \), 
    \[
        T\left( \alpha (x, y, z, t) + \left( x^{\prime} , y^{\prime} , z^{\prime} , t^{\prime}  \right)  \right) = \begin{bmatrix}
            \alpha t + t^{\prime} + \alpha x + x^{\prime}  & \alpha y + y^{\prime} + i(\alpha z + z^{\prime} )  \\
            \alpha y + y^{\prime}  - i(\alpha z + z^{\prime} ) & \alpha t + t^{\prime} - (\alpha x + x^{\prime} )  \\
        \end{bmatrix},
    \]  which is equal to 
    \[
        \begin{bmatrix}
            \alpha t + \alpha x  & \alpha y + i \alpha z  \\
            \alpha y - i \alpha z   & \alpha t - \alpha x 
        \end{bmatrix} + \begin{bmatrix}
            t^{\prime}  + x^{\prime}  & y^{\prime} + i z^{\prime}  \\
            y^{\prime}  - i z^{\prime}  & t^{\prime} - x^{\prime} 
        \end{bmatrix} = \alpha T(x,y,z,t) + T\left( x^{\prime} , y^{\prime} , z^{\prime} ,  t^{\prime}  \right). 
    \] Hence, \(T\) is linear. Now we show that it is bijective. Note that \(\dim \mathbb{R} ^4 = \dim W = 4\), so we just need to check \(T\) is injective. If there exists \((x, y, z, t) \neq (x^{\prime} ,y^{\prime} ,z^{\prime} ,t^{\prime} )\) s.t. \(T(x,y,z,t) = T(x^{\prime} , y^{\prime} , z^{\prime} , t^{\prime} )\), then  
    \[
        \begin{dcases}
            t + x = t^{\prime} + x^{\prime} \\
            y + iz = y^{\prime} + iz^{\prime} \\ 
            y - iz = y^{\prime}  - iz^{\prime} \\
            t - x = t^{\prime}  - x^{\prime} 
        \end{dcases},
    \]   
    and then by adding up the first equation and the last one, we will get \(t = t^{\prime} \) and thus \(x = x^{\prime} \), while adding up the second equation and the third one we have \(y = y^{\prime} \) and \(z = z^{\prime} \), so we know \((x, y, z, t) = \left( x^{\prime} , y^{\prime} , z^{\prime} , t^{\prime}  \right) \), which means \(T\) is injective, and we're done.     
\end{proof}