\begin{problem}
    Let \(W\) be a set of all \((x_1, x_2, x_3, x_4, x_5)\) in \(\mathbb{R} ^5\) which satisfy 
    \[
        \begin{aligned}
        2x_1 &- x_2 &+ \tfrac{4}{3}x_3 &- x_4 & &= 0\\
        x_1  &      &+ \tfrac{2}{3}x_3 & &- x_5 &= 0\\
        9x_1 &- 3x_2 &+ 6x_3           &- 3x_4 &- 3x_5& = 0
        \end{aligned}
    \]
Find a finite set of vectors which spans \(W\). 
\end{problem}
\begin{proof}
    We can first write the system of equations into the matrix form and then use Gaussian elimination.
\begin{align*}
    \begin{pmatrix}
        2 & -1 & \frac{4}{3} & -1 & 0& 0  \\
        1 &  0&  \frac{2}{3}&  0& -1& 0  \\
        9 & -3 & 6 & -3 & -3 &0  \\
    \end{pmatrix} \to \begin{pmatrix}
        1 &  -\frac{1}{2}& \frac{2}{3} & -\frac{1}{2} &  0& 0  \\
        0 &  \frac{1}{2}&  0&  \frac{1}{2}&  -1& 0  \\
        0 &  0&  0&  0&  0&  0 \\
    \end{pmatrix}
\end{align*}
Hence, we can need to solve
\[
    \begin{dcases}
        x_1 - \frac{1}{2}x_2 + \frac{2}{3}x_3 - \frac{1}{2}x_4 = 0 \\
        \frac{1}{2}x_2 + \frac{1}{2} x_4 - x_5 = 0.
    \end{dcases}
\]
So we know \((x_1, _2, x_3, x_4, x_5) = \left( t - \frac{2}{3}a, b, a, 2t - b, t \right) \) for some \(a,b,t \in \mathbb{R} ^5\), and thus we know the set 
\[
    S = \left\{ \left( 1,0,0,2,1 \right), \left( -\frac{2}{3}, 0, 1, 0, 0 \right), \left( 0, 1, 0, -1, 0 \right)   \right\} 
\]  spans \(W\). 
\end{proof}

\begin{problem}
Prove that a subspace of \(\mathbb{R} ^2\)  is \(\mathbb{R} ^2\) , or the zero subspace, or consists of all
scalar multiples of some fixed vector in \(\mathbb{R} ^2\) . (The last type of subspace is, intuitively, a straight line through the origin.)
\end{problem}
\begin{proof}
    We first give a claim: 
    \begin{claim}
        Suppose \(V\) is a vector space, and if \(W\) is a subspace of \(V\), then \(\dim W \le \dim V\).  
    \end{claim}
    \begin{explanation}
        Since \(W \subseteq V\), so suppose \(k=\dim V\) and \(B_1\) is a basis of \(V\), then \(W \subseteq V = span B_1\), which means if there is a basis of \(W\), say \(B_2\), then \(\vert B_2 \vert \le \vert B_1 \vert\), which means \(\dim W \le \dim V\).         
    \end{explanation}

    Now also we know \(\dim \mathbb{R} ^2 = 2\) since \(\left\{ (0,1), (1, 0) \right\} \) is a linearly independent set and spans \(\mathbb{R} ^2\). Thus, if there is a subspace of \(\mathbb{R} ^2\), say \(W\), then \(\dim W = 0, 1, 2\). If \(\dim W = 0\), then \(W\) is the zero subspace. If \(\dim W = 1\), then \(W\) consists of all scalar multiples of some fixed vector in \(\mathbb{R} ^2\). If \(\dim W = 2\), then we can give a claim first: 
    \begin{claim}
        Suppose \(W \subseteq V\) and they are both vector spaces, then if \(\dim V = \dim W\), then \(V = W\).  
    \end{claim}        
    \begin{explanation}
        Suppose by contradiction, there exists \(v \in V \setminus W\), and suppose \(B\) is a basis of \(W\), then we know \(B \cup \left\{ v \right\} \) is linearly independent in \(V\). However, \(\left\vert B \cup \left\{ v \right\}  \right\vert > \dim V \), which is a contradiction.      
    \end{explanation}  
    By this claim, we know \(W = \mathbb{R} ^2\) if \(\dim W = 2\).    
\end{proof}