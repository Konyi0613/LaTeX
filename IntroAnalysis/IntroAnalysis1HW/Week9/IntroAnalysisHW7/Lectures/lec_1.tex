\begin{problem}[15pts]
Assume that $(S,d)$ is a metric space, and let $f_n, f : S \to \mathbb{R}$ be real-valued functions.  
Suppose that $f_n \to f$ uniformly on $S$, and there exists a constant $M > 0$ such that
\[
|f_n(x)| \le M \quad \text{for all } x \in S \text{ and all } n.
\]
Let $g : \overline{B(0;M)} \to \mathbb{R}$ be continuous, where
\[
B(0;M) = \{ y \in \mathbb{R} : |y| < M \}.
\]
Define
\[
h_n(x) = g(f_n(x)), \qquad h(x) = g(f(x)), \quad x \in S.
\]
Prove that $h_n \to h$ uniformly on $S$.
\end{problem}
\begin{proof}
    Since \(g\) is continuous, so for all \(\varepsilon > 0\), there exists \(\delta > 0\) s.t. \(\vert x_1 - x_2 \vert < \delta  \) implies \(\vert g(x_1) - g(x_2) \vert < \varepsilon  \). Also, since \(f_n \to f\) uniformly, so \(\exists N^{\prime} > 0\) s.t. \(n \ge N^{\prime} \) implies \(\left\vert f_n(x) - f(x) \right\vert < \delta \) for all \(x \in S\). Hence, we can pick \(N = N^{\prime} \) so that if \(n \ge N^{\prime} \), then \(\left\vert f_n(x) - f(x) \right\vert < \delta \) for all \(x \in S\) and thus 
    \[
        \left\vert g \left( f_n(x) \right) - g \left( f(x) \right)   \right\vert < \varepsilon 
    \] for all \(x \in S\), so we know \(h_n \to h\) uniformly on \(S\).               
\end{proof}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

\begin{problem}[15pts]
    Let $f_n(x) = x^n$. The sequence $\{f_n\}$ converges pointwise but not uniformly on $[0,1]$.
Let $g$ be continuous on $[0,1]$ with $g(1) = 0$. 
Prove that the sequence $\{ g(x) x^n \}$ converges uniformly on $[0,1]$.
\end{problem}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
\begin{problem}[15pts]
    Assume that $g_{n+1}(x) \le g_n(x)$ for each $x$ in $T$ and each $n = 1, 2, \ldots$, 
and suppose that $g_n \to 0$ uniformly on $T$. 
Prove that 
\[
\sum (-1)^{n+1} g_n(x)
\]
converges uniformly on $T$.
\end{problem}
\begin{proof}
    We first give a claim:
     \begin{claim} \label{clm: gn ge 0}
        \(g_n(x) \ge 0\) for all \(x \in T\) and \(n \in \mathbb{N} \).   
     \end{claim}
     \begin{explanation}
        If \(-c = g_{n_1}(x_1) < 0\) for some \(x_1 \in T\) and \(n_1 \in \mathbb{N} \), then for all \(n \ge n_1\) we have \(g_n(x_1) \le -c\). If we pick some \(\varepsilon \) s.t. \(0 < \varepsilon < c\), then since \(g_n \to 0\) uniformly on \(T\), so there exists \(N > 0\) s.t. \(n \ge N\) implies \(\left\vert g_n(x) \right\vert < \varepsilon < c \) for all \(x \in T\), and thus if we pick \(n_2 = \max \left\{ N, n_1 \right\} \), we know \(g_{n_2}(x_1) \le -c\) and thus \(\left\vert g_{n_2}(x_1) \right\vert \ge c > \varepsilon  \), which is a contradiction.               
     \end{explanation}
     Now we define \(S_n(x) = \sum_{k=1}^n (-1)^{k+1} g_k(x) \). We first show that \[\lim_{n \to \infty} S_n = \sum_{k=1}^{\infty} (-1)^{k+1} g_k(x)  \] exists.
     \begin{claim} \label{clm: Sn bounded (wide)}
        If we fix some \(x \in T\), then 
        \(
            -g_n(x) \le \sum_{k=n}^m (-1)^{k+1} g_k(x) \le g_n(x) 
        \) for all \(n,m \in \mathbb{N} \) and \(x \in T\).  
     \end{claim}   
     \begin{explanation}
        If \(m < n\), then \(\sum_{k=n}^m (-1)^{k+1}g_k(x) = 0 \), so it is true by \autoref{clm: gn ge 0}. If \(m \ge n\), then suppose \(n\) is odd, and then we have
        \begin{align*}
            \sum_{k=n}^m (-1)^{k+1} g_k(x) &= g_n(x) - g_{n+1}(x) + \dots + (-1)^{m} g_m(x) \\
             &= g_n(x) - (g_{n+1}(x) - g_{n+2}(x)) - \dots \le g_n(x)
        \end{align*}
        since \(g_i (x) - g_{i+1}(x) \ge 0\). Also, we know 
        \begin{align*}
            \sum_{k=n}^m (-1)^{k+1} g_k (x) &= g_n(x) - g_{n+1}(x) + \dots + (-1)^m g_m(x) \\
            &= (g_n(x) - g_{n+1}(x)) + (g_{n+2}(x) - g_{n+3}(x)) + \dots \ge 0,
        \end{align*} 
        Thus, for odd \(n\), this statement is true. If \(n\) is even, then we can similarly show that 
        \[
            \sum_{k=n}^m (-1)^{k+1} g_k(x) \ge - g_n(x) \text{ and }  \sum_{k=n}^m (-1)^{k+1} g_k(x) \le 0,
        \] so this is also true.
     \end{explanation}
     Now by \autoref{clm: Sn bounded (wide)} we know \(\left\{ S_n(x) \right\}_{n=1}^{\infty}  \) is bounded for any fixed \(x \in T\), and if we fix \(x_0 \in T\) and suppose 
     \[
        a_k \coloneqq S_{2k-1}(x_0), \quad b_k \coloneqq S_{2k}(x_0), 
     \] then we can check \((a_k)_{k=1}^{\infty} \) is decreasing and \((b_k)_{k=1}^{\infty} \) is increasing, so they are both convergent since they are monotonic and bounded. Also, we know \((\left\vert a_k - b_k \right\vert)_{k=0}^{\infty} \) converges to \(0\) since 
     \[
        \left\vert a_k - b_k \right\vert = \left\vert (-1)^{2k} g_{2k}(x_0) \right\vert = g_{2k}(x_0) 
     \] by \autoref{clm: gn ge 0} and we know \(g_n \to 0\) uniformly. Hence, we know \(\left( a_k \right)_{k=0}^{\infty}  \) and \(\left( b_k \right)_{k=0}^{\infty}  \) converges to same point. Thus, \(\left( S_n(x_0) \right)_{n=1}^{\infty}  \) converges. Note that this argument holds for all \(x_0 \in T\), so we know \(\lim_{n \to \infty} S_n \) exists. 
     
     Now since for all \(\varepsilon > 0\), there exists \(N > 0\) s.t. \(n \ge N\) implies \(g_{n+1}(x) = \left\vert g_{n+1}(x) \right\vert < \varepsilon \) for all \(x \in T\), so \(n \ge N\) implies 
     \begin{align*}
        \left\vert \sum_{k=1}^n (-1)^{k+1} g_k(x) - \sum_{k=1}^{\infty} (-1)^{k+1}g_k(x) \right\vert &= \left\vert \sum_{k=n+1}^{\infty} (-1)^{k+1} g_k(x)  \right\vert \\
        &= \left\vert \lim_{m \to \infty} \sum_{k=n+1}^m (-1)^{k+1} g_k(x) \right\vert \\
        &\le \left\vert \lim_{m \to \infty} g_{n+1}(x) \right\vert  = g_{n+1}(x) < \varepsilon    
     \end{align*}   
     for all \(x \in T\) by \autoref{clm: gn ge 0} and \autoref{clm: Sn bounded (wide)}, which means \(\sum_{n=0}^{\infty} (-1)^{n+1} g_n(x) \) converges uniformly on \(T\).   
\end{proof}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
\begin{problem}[15pts]
\vphantom{text}
\[
f_n(x) = \frac{x}{1 + n x^2}, \quad x \in \mathbb{R}, \; n = 1, 2, \ldots
\]
Find the limit function $f$ of the sequence $\{ f_n \}$ and the limit function $g$ of the sequence $\{ f_n' \}$.

\begin{itemize}
    \item [(a)] Prove that $f'(x)$ exists for every $x$ but that $f'(0) \neq g(0)$. 
    For what values of $x$ is $f'(x) = g(x)$?

    \item [(b)] In what subintervals of $\mathbb{R}$ does $f_n \to f$ uniformly?

    \item [(c)] In what subintervals of $\mathbb{R}$ does $f_n' \to g$ uniformly?
\end{itemize}
\end{problem}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
\begin{problem}[15pts]
    Prove that 
\[
\sum x^n (1 - x)
\]
converges pointwise but not uniformly on $[0,1]$, whereas 
\[
\sum (-1)^n x^n (1 - x)
\]
converges uniformly on $[0,1]$. 
This illustrates that uniform convergence of $\sum f_n(x)$ along with pointwise convergence of $\sum |f_n(x)|$ does not necessarily imply uniform convergence of $\sum |f_n(x)|$.
\end{problem}
\begin{proof}
    Suppose \(S_N(x) = \sum_{n=0}^N x^n(1-x) \), then we know 
    \[
        S_N(x) = (1-x) \sum_{n=0}^N x^n = (1-x) \frac{1 - x^{N+1}}{1-x} = 1 - x^{N+1}. 
    \] 
    Now suppose 
    \[
        f(x) = \begin{dcases}
            1, &\text{ if } x \in [0, 1) ;\\
            0, &\text{ if } x = 1.
        \end{dcases}
    \]
    Then, we claim that \(\sum_{n=0}^{\infty} x^n (1-x) \to f(x) \) pointwise on \([0,1]\). 
    \begin{itemize}
        \item Case 1: \(x = 1\), then for all \(\varepsilon > 0\), we can pick \(N_1 = 1\) so that \(n \ge N_1\) implies 
        \[
            \left\vert S_n(1) - f(1) \right\vert = \left\vert \left( 1 - 1^{n+1} \right) - 0  \right\vert = 0 < \varepsilon.
        \]
        \item Case 2: \(x \in [0,1)\), then for all \(\varepsilon > 0\), we know there exists \(N_2 > 0\) s.t. \(x^{N_2 + 1} < \varepsilon  \). Hence, \(n \ge N_2\) implies 
        \[
            \left\vert S_n(x) - f(x) \right\vert = \left\vert 1 - x^{n+1} - 1 \right\vert = \left\vert x^{n+1} \right\vert = x^{n+1} \le x^{N_2+1} < \varepsilon.   
        \]
    \end{itemize}
    Hence, we're done. Now we show that \(\sum_{n=0}^{\infty} x^n(1-x) \) does not converge uniformly on \([0, 1]\). Suppose by contradiction, \(\sum_{n=0}^{\infty} x^n(1-x) \) converges uniformly to \(f\), then for all \(\varepsilon > 0\), there exists \(N_3 > 0\) s.t. \(n \ge N_3\) implies 
    \[
        \left\vert 1 - x^{n+1} - f(x) \right\vert < \varepsilon \quad \forall x \in [0, 1].
    \] Hence, if we pick some \(n_1, n_2\) s.t. \(n_1 > n_2 \ge N_3\), then we have 
    \[
        \left\vert 1 - x^{n_1 + 1} - f(x) \right\vert < \varepsilon, \quad \left\vert 1 - x^{n_2 + 1} - f(x) \right\vert < \varepsilon, 
    \] so by triangle inequality we have 
    \begin{align*}
        \left\vert x^{n_2 + 1} - x^{n_1 + 1} \right\vert  &= \left\vert 1 - x^{n_1 + 1} - f(x) + \left( -1 + x^{n_2 + 1} + f(x) \right)   \right\vert 
        \\ &\le \left\vert 1 - x^{n_1 + 1} - f(x) \right\vert + \left\vert 1 - x^{n_2 + 1} - f(x) \right\vert < 2 \varepsilon  
    \end{align*}
    Note that 
    \begin{align*}
        x^{n_2 + 1}(1 - x) &= x^{n_2 + 1} - x^{n_2 + 2} \le x^{n_2 + 1} - x^{n_1 + 1} \\
        &= \left\vert x^{n_2 + 1} - x^{n_1 + 1} \right\vert < 2\varepsilon. 
    \end{align*}
    If we pick \(x = 0.5\) and \(\varepsilon \) s.t. \(0 < \varepsilon  < \displaystyle\frac{0.5^{n_2 + 2}}{2}\), then we have 
    \[
        0.5^{n_2 + 2} < 2 \varepsilon < 0.5^{n_2 + 2},
    \] which is a contradiction. Hence, \(\sum_{n=0}^{\infty} x^n(1-x) \) does not converges uniformly. 
    
    Now we show that \(\sum_{n=0}^{\infty} (-1)^n x^n (1-x) \) converges uniformly on \([0, 1]\). Suppose 
    \[
        s_N(x) = \sum_{n=0}^N (-1)^n x^n (1-x) = (1-x) \sum_{n=0}^N (-x)^n = (1-x)\frac{1 - (-x)^{N+1}}{1 - (-x)} = \frac{(1-x)\left( 1 - (-x)^{N+1} \right) }{1+x},   
    \] and \(g(x) = \frac{1-x}{1+x}\), then we claim that \(\sum_{n=0}^{\infty} (-1)^n x^n (1-x) \to g(x) \) uniformly on \([0,1]\). Note that 
    \begin{align*}
        \left\vert s_n(x) - g(x) \right\vert &= \left\vert \frac{1-x}{1+x} \left( 1 - (-x)^{n+1} - 1 \right)  \right\vert = \left\vert \frac{1-x}{1+x}x^{n+1} \right\vert \le (1-x)x^{n+1}. 
    \end{align*}  
    Suppose \(h_n(x) = (1-x)x^{n+1} = x^{n+1} - x^{n+2}\), then 
    \[
        h_n^{\prime} (x) = (n+1)x^n - (n+2) x^{n+1} = x^n \left( (n+1) - (n+2) x \right),
    \] so we know \(h_n\) attains its maximum on \([0, 1]\) at \(x = \frac{n+1}{n+2}\). Hence, we have 
    \begin{align*}
        \left\vert s_n(x) - g(x) \right\vert &\le (1 - x) x^{n+1} \le \left( 1 - \frac{n+1}{n+2} \right)\left( \frac{n+1}{n+2} \right)^{n+1} \\ &= \frac{1}{n+2} \left( 1 - \frac{1}{n+2} \right)^{n+1} = \frac{1}{(n+2)\left( 1 - \frac{1}{n+2} \right)}\frac{1}{\left( 1 + \frac{1}{-(n+2)} \right)^{-(n+2)} } \\
        &= \frac{1}{n+1}\frac{1}{\left( 1 + \frac{1}{-(n+2)} \right)^{-(n+2)} } \to 0 \cdot \frac{1}{e} = 0 \text{ as } n \to \infty. 
    \end{align*} 
    Hence, for all \(\varepsilon > 0\), we can pick some \(N > 0\) s.t. 
    \[
        p(N) = \left( 1 - \frac{N+1}{N+2} \right)\left( \frac{N+1}{N+2} \right)^{N+1} < \varepsilon,
    \] and thus for all \(n \ge N\) we have 
    \[
        \left\vert s_n(x) - g(x) \right\vert \le p(n) \le p(N) < \varepsilon \quad \forall x \in [0,1], 
    \] which means \(\sum_{n=0}^{\infty} (-1)^n x^n (1-x) \to g(x)\) uniformly on \([0, 1]\).  
\end{proof}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
\begin{problem}[15pts]
    Let 
\[
f_n(x) = \frac{1}{n} e^{-n^2 x^2}, \quad x \in \mathbb{R}, \; n = 1, 2, \ldots
\]
Prove that $f_n \to 0$ uniformly on $\mathbb{R}$, that $f_n' \to 0$ pointwise on $\mathbb{R}$,
but that the convergence of $\{ f_n' \}$ is not uniform on any interval containing the origin.
\end{problem}
%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
\begin{problem}[10pts]
    Let $\{ f_n \}$ be a sequence of real-valued continuous functions defined on $[0,1]$
and assume that $f_n \to f$ uniformly on $[0,1]$. 
Prove or disprove
\[
\lim_{n \to \infty} \int_{0}^{1 - 1/n} f_n(x) \, dx = \int_{0}^{1} f(x) \, dx.
\]
\end{problem}
\begin{proof}
    First note that 
    \[
        \int _0^1 f(x) \, \mathrm{d} x = \int _0^1 \lim_{n \to \infty} f_n(x) \, \mathrm{d} x = \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d} x     
    \] since \(f_n \to f\) uniformly on \([0,1]\). Also, since \(f_n\) is continuous and defined on \([0, 1]\) for all \(n \in \mathbb{N} \), so by Extreme value theorem we know \(f_n(x) \le M\) for some \(M \in \mathbb{R} \) for all \(n \in \mathbb{N} \). Hence, we know 
    \[
        \int _0^1 f_n(x) \, \mathrm{d} x - \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x = \int _{1 - \frac{1}{n}}^1 f_n(x) \, \mathrm{d} x \le M \cdot \frac{1}{n} \quad \forall n \in \mathbb{N}.  
    \] Hence, for all \(\varepsilon > 0\) we can pick some \(N > 0\) s.t. \(M \cdot \frac{1}{N} < \varepsilon \) so that \(n \ge N\) implies 
    \[
        \int _0^1 f_n(x) \, \mathrm{d}x - \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x \le M \cdot \frac{1}{n} \le M \cdot \frac{1}{N} < \varepsilon,  
    \] which means
    \[
        \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d}x - \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x = 0, 
    \] so 
    \[
        \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d}x = \lim_{n \to \infty} \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x,
    \] and thus 
    \[
        \int _0^1 f(x) \, \mathrm{d} x = \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d}x = \lim_{n \to \infty} \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x,
    \] and we're done.
    \begin{remark}
        Since \(f_n\) is continuous and defined on \([0, 1]\), so \(f_n\) is Riemann integrable and thus \(f\) is Riemann integrable. Hence, we know
        \[
            \int _0^1 f(x) \, \mathrm{d} x = \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d} x    
        \] exists. Hence, we know 
        \begin{align*}
            -\lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d}x &= \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d}x - \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x - \lim_{n \to \infty} \int _0^1 f_n(x) \, \mathrm{d} x \\ &= \lim_{n \to \infty} \left( \int _0^1 f_n(x) \, \mathrm{d}x - \int _0^{1 - \frac{1}{n}} f_n(x) \, \mathrm{d} x - \int _0^1 f_n(x) \, \mathrm{d} x \right) \\
            &= \lim_{n \to \infty} -\int _0^{1 - \frac{1}{n}}f_n(x) \, \mathrm{d} x  
        \end{align*}
        exists. These are some details about why we can operate the limit as above.
    \end{remark}
\end{proof}