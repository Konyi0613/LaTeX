\chapter{Some Extra proof}
\section{Uncategorized}
\begin{theorem} \label{thm: if subseq of cauchy converge, then cauchy converge to same point}
    For a Cauchy sequence \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \), if there exists a subsequence \(\left\{ x^{(n_j)} \right\}_{j=1}^{\infty}  \) converges to \(x\), then \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \) also converges to \(x\).   
\end{theorem}
\begin{proof}
    For all \(\varepsilon > 0\), we know there exists \(N > 0\) s.t. \(j \ge N\) implies 
    \[
        d\left( x^{(n_j)}, x \right) < \frac{\varepsilon}{2}. 
    \]  
    Also, there exists \(N^{\prime} > 0\) s.t. \(i, j \ge N^{\prime} \) implies
    \[
        d\left( x^{(i)}, x^{(j)} \right) < \frac{\varepsilon}{2}. 
    \]  
    Hence, if we pick some \(d \ge N\) and \(n_d \ge N^{\prime} \), then we know for all \(n \ge N^{\prime} \), we have 
    \[
        d \left( x^{(n)}, x \right) \le d \left( x^{(n)}, x^{(n_d)} \right) + d \left( x^{(n_d)}, x \right) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon,
    \] which means \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \) converges to \(x\).  
\end{proof}


\begin{definition}
    A sequence of intervals \(I_n\) (\(n \in \mathbb{N} \)) is nested if \(I_n \neq \varnothing \) and \(I_{n+1} \subseteq I_n\) for all \(n \in \mathbb{N}\). (\(I_1 \supseteq I_2 \supseteq \dots\)).     
\end{definition}

Now we want to know \(\bigcap_{n \in \mathbb{N} }^{\infty} I_n \neq \varnothing \)?

Here is some counterexamples. Consider \(I_n = (0, \frac{1}{n})\), \(n \in \mathbb{N} \). We can show that \(\bigcap_{n=1}^{\infty} I_n = \varnothing  \) by Archimedean Property. Besides, if \(I_n = [n, \infty )\), \(n \in \mathbb{N} \), this is trivial that \(\bigcap_{n=1}^{\infty} I_n = \varnothing  \). 

\begin{theorem}[Theorem of nested intervals]\label{thm: nested interval}
    If \(I_n\) (\(n \in \mathbb{N} \)) is a sequence of bounded closed nested intervals, then \(\bigcap_{n=1}^{\infty} I_n \neq \varnothing  \).  
\end{theorem}

\begin{proof}
    Write \(I_n = [a_n,b_n]\) for all \(n \in \mathbb{N} \). First, we know \(I_n\) is nested iff \(a_n \le b_n\) and \(a_n\) is nondecreasing and \(b_n\) is nonincreasing. Hence, \(\forall n,m \in \mathbb{N} \), we have \(a_n \le a_{\max \left\{ n,m \right\} } \le b_{\max \left\{ n,m \right\} } \le b_m\). In other words, for every \(m \in \mathbb{N} \), \(b_m\) is a upper bound of \(\left\{ a_n \right\} \). Hence, we know \(c = \lim_{n \to \infty} a_n  = \sup \left\{ a_n \right\} \).exists. Then, \(c \le b_m\) for all \(m \in \mathbb{N} \). Also, \(c \ge a_n\) for all \(n \in \mathbb{N} \). Hence, \(a_n \le c \le b_n\) for all \(n \in \mathbb{N} \), and thus we know \(c \in I_n\) for all \(n \in \mathbb{N} \). Thus, \(c \in \bigcap_{n=1}^{\infty} I_n \).                     
\end{proof}

\begin{theorem}[Bolzano Weierstrass Theorem] \label{thm: Bolzano Weierstrass thm}
    Suppose we have a bounded infinite sequence \(a_n \in \mathbb{R} ^m\), then \(\exists \) a subsequence \(a_{n(m)}\) such that \(a_{n(m)}\) is convergent.   
\end{theorem}
\begin{proof}
    We just talk about the case \(m=2\), and the higher case is similar. Choose \(M>0\) such that \(a_n \in [-M,M] \times [-M,M]\) for all \(n \in \mathbb{N} \). Suppose \([-M,M] \times [-M,M]\) is called \(Q\). Divide \(Q\) into \(4\) squares with equal size, and choose one, say \(Q_1\) such that \(\left\vert \left\{ n \mid a_n \in Q_1 \right\} = \infty   \right\vert \). Select \(n_1 \in \mathbb{N} \) such that \(a_{n_1} \in Q_1\). Repeat this step, that is, divide \(Q_1\) into \(4\) subparts, then says the one subpart with infinite many \(a_n\) in it is \(Q_2\) (\(Q_2\) must exists). Select \(n_2 \in \mathbb{N} \) such that \(a_{n_2} \in Q_2\) and \(n_2 > n_1\). Keep repeating this step, then by \autoref{thm: nested interval} we know
    \[
        \bigcap_{n=1}^{\infty} Q_n \neq \varnothing.
    \] 
    \begin{note}
        Just think of the nested intervals are in \(x\) and \(y\) directions.  
    \end{note}
    Actually, \(\bigcap_{n=1}^{\infty} Q_n = \left\{ a \right\} \) for some \(a \in \mathbb{R} ^2\), otherwise if there are two points in the intersection, then at some moment we will divide them into different subpart, which is a contradiction. It can been seen that \(\lim_{k \to \infty} a_{n(k)} = a\).   
\end{proof}

\begin{theorem} \label{thm: two seq d converge to 0 implies converge to same point}
    If \((X, d)\) is a metric space and \(\left\{ a_n \right\}_{n=1}^{\infty} , \left\{ b_n \right\}_{n=1}^{\infty} \subseteq X  \). Now if \(\lim_{n \to \infty} d(a_n, b_n) = 0 \) and \(\lim_{n \to \infty} a_n = p \) for some \(p \in X\), then \(\lim_{n \to \infty} b_n = p \).      
\end{theorem}
\begin{proof}
    Since we know for all \(\varepsilon > 0\), \(\exists N > 0\) s.t. \(n \ge N\) implies \(d(a_n, p) < \varepsilon \), and there exists \(N_1, N_2 > 0\) s.t. \(n \ge N_1\) implies \(d(b_n, a_n) < \frac{\varepsilon}{2}\) and \(n \ge N_2\) implies \(d(a_n, p) < \frac{\varepsilon}{2}\), so now for \(n \ge \max \left\{ N_1, N_2 \right\} \), we know 
    \[
        d(b_n, p) = d(b_n, a_n) + d(a_n, p) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} =\varepsilon .
    \]          
\end{proof}

\begin{theorem} \label{thm: if sup exists then a sequence in S converges to supS}
    If \(S \subseteq \mathbb{R} \), and \(\sup S\) exists for some set \(S\), then there exists a sequence of \(S\) converging to \(\sup S\).    
\end{theorem}
\begin{proof}
    By the definition of sup, we know for all \(\varepsilon > 0\), \(\exists s \in S\) s.t. \(\sup S \ge s > \sup S - \varepsilon \), so pick \(\varepsilon = \frac{1}{n}\) for all \(n \in \mathbb{N} \), we can form \(\left( s^{(n)} \right)_{n=1}^{\infty}  \) convergeing to \(\sup S\).        
\end{proof}

\section{The uniqueness of the convergence of function}
\begin{theorem} \label{thm: uniqueness of pointwise convergence}
    If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges pointwise to \(f\) and converges pointwise to \(g\), then \(f = g\).  
\end{theorem}
\begin{proof}
    Write down the definition and use triangle inequality.
\end{proof}

\begin{theorem} \label{thm: uniqueness of uniform convergence}
    If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and converges uniformly to \(g\), then \(f = g\).    
\end{theorem}
\begin{proof}
    Since uniform convergence implies pointwise convergence, so \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and \(g\), so \(f = g\) by \autoref{thm: uniqueness of pointwise convergence}.    
\end{proof}

\begin{theorem}
        If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and converges pointwise to \(g\), then \(f = g\). 
\end{theorem}
\begin{proof}
    Since uniform convergence implies pointwise convergence, so \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges pointwise to \(f\), and by \autoref{thm: uniqueness of pointwise convergence}, we know \(f = g\).    
\end{proof}
\newpage
\section{Continuity of power series}
\begin{theorem}
    If \(f(x)\) is real analytic at \(a\), then suppose 
    \[
        f(x) = \sum_{n=0}^{\infty} c_n (x-a)^n, \quad \text{converges for all }  x \in (a-r,a+r)  
    \] where \(r > 0\), then \(f\) is continuous on \((a-r, a+r)\).   
\end{theorem}
\begin{proof}[Differentiable perspective]
    Since \(f\) is differentiable on \((a-r,a+r)\) by \autoref{thm: convergence of power series about radius of convergence}, and differentiability implies continuity, so we know \(f\) is continuous on \((a-r,a+r)\).     
\end{proof}

\begin{proof}[Uniform convergence perspective]
    We first give a lemma:
\begin{lemma} \label{lm: uniform convergence preserving continuity}
    Suppose \(f^{(n)} : X \to \mathbb{R} \) and \(f:X \to \mathbb{R} \) for some metric space \(X\), then if \(\left( f^{(n)} \right)_{n=1}^{\infty} \to f \) uniformly and \(f^{(n)}\) is continuous for all \(n \in \mathbb{N} \), then \(f\) is continuous.   
\end{lemma}
\begin{proof}
    Note that for \(x, x_0 \in X\), we have 
    \[
        \left\vert f(x) - f(x_0) \right\vert \le \left\vert f(x) - f^{(N)}(x) \right\vert + \left\vert f^{(N)}(x) - f^{(x_0)} \right\vert + \left\vert f^{(N)}(x_0) - f(x_0) \right\vert, 
    \] and R.H.S. can be arbitrarily small if we pick \(x, x_0\) close enough due to the uniform convergence and continuity. 
\end{proof}
By this lemma, we can deduce the continuity of \(f\) since 
\[
    f(x) = \sum_{n=0}^{\infty} c_n(x-a)^n 
\] is uniformly convergent on \((a-r, a+r)\) and the partial sum \(S_n\) is continuous.  
\end{proof}
\section{Some test for convergence of series}
\begin{theorem}[Necessary Condition for Convergence]
If the series $\sum a_n$ converges, then $\lim_{n \to \infty} a_n = 0$.
\end{theorem}

\begin{theorem}[Direct Comparison Test]
Suppose $0 \le a_n \le b_n$ for all sufficiently large $n$.
\begin{itemize}
    \item If $\sum b_n$ converges, then $\sum a_n$ converges.
    \item If $\sum a_n$ diverges, then $\sum b_n$ diverges.
\end{itemize}
\end{theorem}

\begin{theorem}[Limit Comparison Test]
Let $a_n, b_n > 0$ for all $n$. If
\[
\lim_{n \to \infty} \frac{a_n}{b_n} = c, \quad 0 < c < \infty,
\]
then either both $\sum a_n$ and $\sum b_n$ converge or both diverge.
\end{theorem}

\begin{theorem}[Ratio Test (d'Alembert)]
Let $a_n \ne 0$ and define
\[
L = \lim_{n \to \infty} \left| \frac{a_{n+1}}{a_n} \right|.
\]
Then:
\begin{itemize}
    \item If $L < 1$, the series $\sum a_n$ converges absolutely.
    \item If $L > 1$, the series diverges.
    \item If $L = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}

\begin{theorem}[Root Test (Cauchy)]
Let
\[
L = \lim_{n \to \infty} \sqrt[n]{|a_n|}.
\]
Then:
\begin{itemize}
    \item If $L < 1$, the series $\sum a_n$ converges absolutely.
    \item If $L > 1$, the series diverges.
    \item If $L = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}

\begin{theorem}[Integral Test]
Let $f(x)$ be continuous, positive, and decreasing on $[1, \infty)$, and let $a_n = f(n)$. Then
\[
\sum_{n=1}^{\infty} a_n \text{ converges } \iff \int_1^{\infty} f(x)\,dx \text{ converges.}
\]
\end{theorem}

\begin{theorem}[Alternating Series Test (Leibniz)]
If $(a_n)$ is a decreasing sequence of positive numbers with $\lim_{n \to \infty} a_n = 0$, then
\[
\sum_{n=1}^{\infty} (-1)^{n} a_n
\]
converges.
\end{theorem}

\begin{theorem}[$p$-Series Test]
The series
\[
\sum_{n=1}^{\infty} \frac{1}{n^p}
\]
converges if and only if $p > 1$.
\end{theorem}

\begin{theorem}[Geometric Series Test]
The series
\[
\sum_{n=0}^{\infty} ar^n
\]
converges if and only if $|r| < 1$, in which case the sum equals $\dfrac{a}{1 - r}$.
\end{theorem}

\begin{theorem}[Raabe’s Test]
Let $a_n > 0$ and define
\[
R = \lim_{n \to \infty} n\left( \frac{a_n}{a_{n+1}} - 1 \right).
\]
Then:
\begin{itemize}
    \item If $R > 1$, the series $\sum a_n$ converges.
    \item If $R < 1$, the series diverges.
    \item If $R = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}


%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

\chapter{TA Class}