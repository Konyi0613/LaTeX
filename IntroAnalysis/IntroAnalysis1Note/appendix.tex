\chapter{Some Extra proof}
\section{Uncategorized}
\begin{theorem} \label{thm: if subseq of cauchy converge, then cauchy converge to same point}
    For a Cauchy sequence \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \), if there exists a subsequence \(\left\{ x^{(n_j)} \right\}_{j=1}^{\infty}  \) converges to \(x\), then \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \) also converges to \(x\).   
\end{theorem}
\begin{proof}
    For all \(\varepsilon > 0\), we know there exists \(N > 0\) s.t. \(j \ge N\) implies 
    \[
        d\left( x^{(n_j)}, x \right) < \frac{\varepsilon}{2}. 
    \]  
    Also, there exists \(N^{\prime} > 0\) s.t. \(i, j \ge N^{\prime} \) implies
    \[
        d\left( x^{(i)}, x^{(j)} \right) < \frac{\varepsilon}{2}. 
    \]  
    Hence, if we pick some \(d \ge N\) and \(n_d \ge N^{\prime} \), then we know for all \(n \ge N^{\prime} \), we have 
    \[
        d \left( x^{(n)}, x \right) \le d \left( x^{(n)}, x^{(n_d)} \right) + d \left( x^{(n_d)}, x \right) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon,
    \] which means \(\left\{ x^{(n)} \right\}_{n=1}^{\infty}  \) converges to \(x\).  
\end{proof}


\begin{definition}
    A sequence of intervals \(I_n\) (\(n \in \mathbb{N} \)) is nested if \(I_n \neq \varnothing \) and \(I_{n+1} \subseteq I_n\) for all \(n \in \mathbb{N}\). (\(I_1 \supseteq I_2 \supseteq \dots\)).     
\end{definition}

Now we want to know \(\bigcap_{n \in \mathbb{N} }^{\infty} I_n \neq \varnothing \)?

Here is some counterexamples. Consider \(I_n = (0, \frac{1}{n})\), \(n \in \mathbb{N} \). We can show that \(\bigcap_{n=1}^{\infty} I_n = \varnothing  \) by Archimedean Property. Besides, if \(I_n = [n, \infty )\), \(n \in \mathbb{N} \), this is trivial that \(\bigcap_{n=1}^{\infty} I_n = \varnothing  \). 

\begin{theorem}[Theorem of nested intervals]\label{thm: nested interval}
    If \(I_n\) (\(n \in \mathbb{N} \)) is a sequence of bounded closed nested intervals, then \(\bigcap_{n=1}^{\infty} I_n \neq \varnothing  \).  
\end{theorem}

\begin{proof}
    Write \(I_n = [a_n,b_n]\) for all \(n \in \mathbb{N} \). First, we know \(I_n\) is nested iff \(a_n \le b_n\) and \(a_n\) is nondecreasing and \(b_n\) is nonincreasing. Hence, \(\forall n,m \in \mathbb{N} \), we have \(a_n \le a_{\max \left\{ n,m \right\} } \le b_{\max \left\{ n,m \right\} } \le b_m\). In other words, for every \(m \in \mathbb{N} \), \(b_m\) is a upper bound of \(\left\{ a_n \right\} \). Hence, we know \(c = \lim_{n \to \infty} a_n  = \sup \left\{ a_n \right\} \).exists. Then, \(c \le b_m\) for all \(m \in \mathbb{N} \). Also, \(c \ge a_n\) for all \(n \in \mathbb{N} \). Hence, \(a_n \le c \le b_n\) for all \(n \in \mathbb{N} \), and thus we know \(c \in I_n\) for all \(n \in \mathbb{N} \). Thus, \(c \in \bigcap_{n=1}^{\infty} I_n \).                     
\end{proof}

\begin{theorem}[Bolzano Weierstrass Theorem] \label{thm: Bolzano Weierstrass thm}
    Suppose we have a bounded infinite sequence \(a_n \in \mathbb{R} ^m\), then \(\exists \) a subsequence \(a_{n(m)}\) such that \(a_{n(m)}\) is convergent.   
\end{theorem}
\begin{proof}
    We just talk about the case \(m=2\), and the higher case is similar. Choose \(M>0\) such that \(a_n \in [-M,M] \times [-M,M]\) for all \(n \in \mathbb{N} \). Suppose \([-M,M] \times [-M,M]\) is called \(Q\). Divide \(Q\) into \(4\) squares with equal size, and choose one, say \(Q_1\) such that \(\left\vert \left\{ n \mid a_n \in Q_1 \right\} = \infty   \right\vert \). Select \(n_1 \in \mathbb{N} \) such that \(a_{n_1} \in Q_1\). Repeat this step, that is, divide \(Q_1\) into \(4\) subparts, then says the one subpart with infinite many \(a_n\) in it is \(Q_2\) (\(Q_2\) must exists). Select \(n_2 \in \mathbb{N} \) such that \(a_{n_2} \in Q_2\) and \(n_2 > n_1\). Keep repeating this step, then by \autoref{thm: nested interval} we know
    \[
        \bigcap_{n=1}^{\infty} Q_n \neq \varnothing.
    \] 
    \begin{note}
        Just think of the nested intervals are in \(x\) and \(y\) directions.  
    \end{note}
    Actually, \(\bigcap_{n=1}^{\infty} Q_n = \left\{ a \right\} \) for some \(a \in \mathbb{R} ^2\), otherwise if there are two points in the intersection, then at some moment we will divide them into different subpart, which is a contradiction. It can been seen that \(\lim_{k \to \infty} a_{n(k)} = a\).   
\end{proof}

\begin{theorem} \label{thm: two seq d converge to 0 implies converge to same point}
    If \((X, d)\) is a metric space and \(\left\{ a_n \right\}_{n=1}^{\infty} , \left\{ b_n \right\}_{n=1}^{\infty} \subseteq X  \). Now if \(\lim_{n \to \infty} d(a_n, b_n) = 0 \) and \(\lim_{n \to \infty} a_n = p \) for some \(p \in X\), then \(\lim_{n \to \infty} b_n = p \).      
\end{theorem}
\begin{proof}
    Since we know for all \(\varepsilon > 0\), \(\exists N > 0\) s.t. \(n \ge N\) implies \(d(a_n, p) < \varepsilon \), and there exists \(N_1, N_2 > 0\) s.t. \(n \ge N_1\) implies \(d(b_n, a_n) < \frac{\varepsilon}{2}\) and \(n \ge N_2\) implies \(d(a_n, p) < \frac{\varepsilon}{2}\), so now for \(n \ge \max \left\{ N_1, N_2 \right\} \), we know 
    \[
        d(b_n, p) = d(b_n, a_n) + d(a_n, p) < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} =\varepsilon .
    \]          
\end{proof}

\begin{theorem} \label{thm: if sup exists then a sequence in S converges to supS}
    If \(S \subseteq \mathbb{R} \), and \(\sup S\) exists for some set \(S\), then there exists a sequence of \(S\) converging to \(\sup S\).    
\end{theorem}
\begin{proof}
    By the definition of sup, we know for all \(\varepsilon > 0\), \(\exists s \in S\) s.t. \(\sup S \ge s > \sup S - \varepsilon \), so pick \(\varepsilon = \frac{1}{n}\) for all \(n \in \mathbb{N} \), we can form \(\left( s^{(n)} \right)_{n=1}^{\infty}  \) convergeing to \(\sup S\).        
\end{proof}

\section{The uniqueness of the convergence of function}
\begin{theorem} \label{thm: uniqueness of pointwise convergence}
    If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges pointwise to \(f\) and converges pointwise to \(g\), then \(f = g\).  
\end{theorem}
\begin{proof}
    Write down the definition and use triangle inequality.
\end{proof}

\begin{theorem} \label{thm: uniqueness of uniform convergence}
    If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and converges uniformly to \(g\), then \(f = g\).    
\end{theorem}
\begin{proof}
    Since uniform convergence implies pointwise convergence, so \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and \(g\), so \(f = g\) by \autoref{thm: uniqueness of pointwise convergence}.    
\end{proof}

\begin{theorem}
        If \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges uniformly to \(f\) and converges pointwise to \(g\), then \(f = g\). 
\end{theorem}
\begin{proof}
    Since uniform convergence implies pointwise convergence, so \(\left( f^{(n)} \right)_{n=1}^{\infty}  \) converges pointwise to \(f\), and by \autoref{thm: uniqueness of pointwise convergence}, we know \(f = g\).    
\end{proof}
\newpage
\section{Continuity of power series}
\begin{theorem}
    If \(f(x)\) is real analytic at \(a\), then suppose 
    \[
        f(x) = \sum_{n=0}^{\infty} c_n (x-a)^n, \quad \text{converges for all }  x \in (a-r,a+r)  
    \] where \(r > 0\), then \(f\) is continuous on \((a-r, a+r)\).   
\end{theorem}
\begin{proof}[Differentiable perspective]
    Since \(f\) is differentiable on \((a-r,a+r)\) by \autoref{thm: convergence of power series about radius of convergence}, and differentiability implies continuity, so we know \(f\) is continuous on \((a-r,a+r)\).     
\end{proof}

\begin{proof}[Uniform convergence perspective]
    We first give a lemma:
\begin{lemma} \label{lm: uniform convergence preserving continuity}
    Suppose \(f^{(n)} : X \to \mathbb{R} \) and \(f:X \to \mathbb{R} \) for some metric space \(X\), then if \(\left( f^{(n)} \right)_{n=1}^{\infty} \to f \) uniformly and \(f^{(n)}\) is continuous for all \(n \in \mathbb{N} \), then \(f\) is continuous.   
\end{lemma}
\begin{proof}
    Note that for \(x, x_0 \in X\), we have 
    \[
        \left\vert f(x) - f(x_0) \right\vert \le \left\vert f(x) - f^{(N)}(x) \right\vert + \left\vert f^{(N)}(x) - f^{(x_0)} \right\vert + \left\vert f^{(N)}(x_0) - f(x_0) \right\vert, 
    \] and R.H.S. can be arbitrarily small if we pick \(x, x_0\) close enough due to the uniform convergence and continuity. 
\end{proof}
By this lemma, we can deduce the continuity of \(f\) since 
\[
    f(x) = \sum_{n=0}^{\infty} c_n(x-a)^n 
\] is uniformly convergent on \((a-r, a+r)\) and the partial sum \(S_n\) is continuous.  
\end{proof}
\section{Some test for convergence of series}
\begin{theorem}[Necessary Condition for Convergence]
If the series $\sum a_n$ converges, then $\lim_{n \to \infty} a_n = 0$.
\end{theorem}

\begin{theorem}[Direct Comparison Test]
Suppose $0 \le a_n \le b_n$ for all sufficiently large $n$.
\begin{itemize}
    \item If $\sum b_n$ converges, then $\sum a_n$ converges.
    \item If $\sum a_n$ diverges, then $\sum b_n$ diverges.
\end{itemize}
\end{theorem}

\begin{theorem}[Limit Comparison Test]
Let $a_n, b_n > 0$ for all $n$. If
\[
\lim_{n \to \infty} \frac{a_n}{b_n} = c, \quad 0 < c < \infty,
\]
then either both $\sum a_n$ and $\sum b_n$ converge or both diverge.
\end{theorem}

\begin{theorem}[Ratio Test (d'Alembert)]
Let $a_n \ne 0$ and define
\[
L = \lim_{n \to \infty} \left| \frac{a_{n+1}}{a_n} \right|.
\]
Then:
\begin{itemize}
    \item If $L < 1$, the series $\sum a_n$ converges absolutely.
    \item If $L > 1$, the series diverges.
    \item If $L = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}

\begin{theorem}[Root Test (Cauchy)]
Let
\[
L = \lim_{n \to \infty} \sqrt[n]{|a_n|}.
\]
Then:
\begin{itemize}
    \item If $L < 1$, the series $\sum a_n$ converges absolutely.
    \item If $L > 1$, the series diverges.
    \item If $L = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}

\begin{theorem}[Integral Test]
Let $f(x)$ be continuous, positive, and decreasing on $[1, \infty)$, and let $a_n = f(n)$. Then
\[
\sum_{n=1}^{\infty} a_n \text{ converges } \iff \int_1^{\infty} f(x)\,dx \text{ converges.}
\]
\end{theorem}

\begin{theorem}[Alternating Series Test (Leibniz)]
If $(a_n)$ is a decreasing sequence of positive numbers with $\lim_{n \to \infty} a_n = 0$, then
\[
\sum_{n=1}^{\infty} (-1)^{n} a_n
\]
converges.
\end{theorem}

\begin{theorem}[$p$-Series Test]
The series
\[
\sum_{n=1}^{\infty} \frac{1}{n^p}
\]
converges if and only if $p > 1$.
\end{theorem}

\begin{theorem}[Geometric Series Test]
The series
\[
\sum_{n=0}^{\infty} ar^n
\]
converges if and only if $|r| < 1$, in which case the sum equals $\dfrac{a}{1 - r}$.
\end{theorem}

\begin{theorem}[Raabe’s Test]
Let $a_n > 0$ and define
\[
R = \lim_{n \to \infty} n\left( \frac{a_n}{a_{n+1}} - 1 \right).
\]
Then:
\begin{itemize}
    \item If $R > 1$, the series $\sum a_n$ converges.
    \item If $R < 1$, the series diverges.
    \item If $R = 1$, the test is inconclusive.
\end{itemize}
\end{theorem}


%────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

\chapter{TA Class}
\section{Week 12}
\begin{problem}[HW7 Q4]
    Suppose \(f_n(x) = \frac{x}{1+nx^2}\), where \(x \in \mathbb{R} \) for \(n = 1,2, \dots \). Define \(f(x) = \lim_{n \to \infty} f_n(x)\) and \(g(x) = \lim_{n \to \infty} f_n^{\prime} (x) \). 
    \begin{itemize}
        \item [(a)] Prove \(f^{\prime} (x)\) exists for all \(x \in \mathbb{R} \), but that \(f^{\prime} (0) \neq g(0)\). For what values of \(x\) is \(f^{\prime} (x) = g(x)\)? 
        \item [(b)] In what intervals of \(\mathbb{R} \) does \(f_n \to f\) uniformly?   
        \item [(c)] In what intervals of \(\mathbb{R} \) does \(f_n^{\prime} \to g\) uniformly?     
    \end{itemize}     
\end{problem}
\begin{proof}[proof of (a)]
    For \(x = 0\), \(f_n(0) = 0\) for all \(n \in \mathbb{N} \), so \(f(0) = \lim_{n \to \infty} f_n(0) = 0 \). For \(x \neq 0\), we know 
    \[
        f_n(x) = \frac{x}{1+nx} = \frac{1}{n} \frac{1}{x \left( 1 + \frac{1}{nx^2} \right) } \le \frac{1}{n} \frac{1}{x} \to 0 \text{ as } n \to \infty. 
    \]    
    Hence, \(f(x) = \lim_{n \to \infty} f_n^{\prime} (x) = 0\). Thus, \(f(x) = 0\) on \(\mathbb{R} \). Now compute 
    \[
        f_n^{\prime} (x) = \frac{1 - nx^2}{\left( 1 + nx^2 \right)^2 },
    \] for \(x = 0\), we know \(f_n^{\prime} (0) = \frac{1-0}{(1+0)^2} = 1\) for all \(n \in \mathbb{N} \) and thus \(g(0) = 1\). For \(x \neq 0\), 
    \[
        \left\vert f_n^{\prime} (x) \right\vert = \left\vert \frac{1}{n} \frac{-1 + \frac{1}{nx^2}}{x^2 \left( 1 + \frac{1}{nx^2} \right) }  \right\vert \le \frac{1}{n} \frac{1}{x^2} \to 0 \text{ as } n \to  \infty,   
    \] so \(g(x) = 0\). Hence, 
    \[
        g(x) = \begin{dcases}
            1, &\text{ if }  x=0;\\
            0, &\text{ if }  x\neq 0.
        \end{dcases}
    \] 
\end{proof}

\begin{proof}[proof of (b)]
It suffices to show 
\[
    \sup _{x \in \mathbb{R} } \left\vert f_n(x) - f(x) \right\vert \to 0 \text{ as } n \to \infty. 
\]
Define \(\varphi _n(x) = \left\vert f_n(x) \right\vert = \left\vert \frac{x}{1 + nx^2} \right\vert  \), then \(\varphi _n(x)\) is even, so we only need to study \(x \ge 0\). Consider \(x > 0\), then 
\[
    \varphi _n(x) = \frac{x}{1 + nx^2} \implies \varphi _n^{\prime} (x) = \frac{\left( 1 + nx^2 \right) - x(2nx) }{\left( 1 + nx^2 \right)^2 } = \frac{1 - nx^2}{\left( 1 + nx^2 \right)^2 },
\] so \(\varphi _n^{\prime} (x) = 0\) iff \(1 - nx^2 = 0\), which means \(x = \frac{1}{\sqrt{n} }\) is the critical point, and since \(\varphi _n(x)\) is decreasing for \(x > \frac{1}{\sqrt{n} }\), so \(\varphi _n \left( \frac{1}{\sqrt{n} } \right) \) attains the maximum on \((0, \infty )\). Hence, 
\[
    \sup _{x \in \mathbb{R} }\left\vert f_n(x) - f(x) \right\vert = \varphi _n \left( \frac{1}{\sqrt{n} } \right) = \frac{1}{2\sqrt{n} } \to 0 \text{ as } n \to  \infty .  
\]      
Hence, we can conclude that \(f_n \to f\) uniformly. 
\end{proof}

\begin{proof}[proof of (c)]
\vphantom{text}
\begin{itemize}
    \item Case 1: If \(0 \notin \overline{I} \), then \(\exists a > 0\) s.t. \(\forall x \in I\), \(\vert x \vert \ge a\). Hence, \(g(x) = 0\) for all \(x \in I\), so \(g(x) = 0\) for all \(x \in I\). Now 
    \[
        \left\vert f_n^{\prime} (x) \right\vert = \left\vert \frac{1 - nx^2}{\left( 1 + nx^2 \right)^2 } \right\vert \le \frac{1 + nx^2}{\left( 1 + nx^2 \right)^2 } = \frac{1}{1 + nx^2} \le \frac{1}{1 + an^2} \to 0 \text{ as } n \to  \infty \quad \forall x \in I.   
    \]
    Hence, \(f_n^{\prime} \to g\) uniformly on \(I\).  
    \item Case 2: \(0 \in \overline{I} \), then there exists \(b > 0\) s.t. \([-b, 0) \subseteq I\) or \((0, b] \subseteq I\). Note that 
    \[
        f_n^{\prime} (x) = \frac{1 - nx^2}{\left( 1+nx^2 \right)^2 }.
    \] Consider \(x_n = \frac{1}{2\sqrt{n} }\) if \((0, b] \subseteq I\) (or \(x_n = -\frac{1}{2\sqrt{n} }\) is \([-b, 0) \subseteq I\)). When \(n\) is large, we see that \(\vert x_n \vert < b \). Then, \(\exists N \in \mathbb{N} \) s.t. \(\forall n \ge N\), we have \(x_n \in I\), and 
    \[
        f_n^{\prime} \left( x_n \right) = \frac{1 - n \left( \frac{1}{2\sqrt{n} } \right)^2 }{\left( 1 + n \left( \frac{1}{2\sqrt{n} } \right)^2  \right)^2 } = \frac{\frac{3}{4}}{\frac{25}{16}} = \frac{12}{25} \quad \forall n \ge N. 
    \]
    Hence, 
    \[
        \sup _{x \in I} \left\vert f_n^{\prime} (x) - g(x) \right\vert \ge \left\vert f_n^{\prime} (x_n) - 0 \right\vert = \frac{12}{25} \quad \forall n \ge N,
    \] so it is not uniformly convergent.
\end{itemize}
\end{proof}

\begin{problem}[HW7 Q6]
    Suppose \(f_n(x) = \frac{1}{n} e^{-n^2 x^2}\) for \(x \in \mathbb{R} \) and \(n = 1,2, \dots \). Prove that \(f_n \to 0\) uniformly in \(\mathbb{R} \). Show that \(f_n^{\prime} \to 0\) pointwise in \(\mathbb{R} \) but not uniformly on any interval containing \(0\).       
\end{problem}
\begin{proof}
Note that 
\[
    \left\vert f_n(x) \right\vert \le \frac{1}{n} \text{ since } e^{-n^2 x^2} \le 1 \quad \forall x \in \mathbb{R}.  
\]
Hence, 
\[
    \sup _{x \in \mathbb{R} } \left\vert f(x) \right\vert = \frac{1}{n} \to 0 \text{ as } n \to \infty,
\] so \(f_n \to 0\) uniformly in \(\mathbb{R} \). Now note that 
\[
    f_n^{\prime} (x) = 2nx e^{-n^2 x^2}.
\] For \(x = 0\), we have \(f_n^{\prime} (0) = 0\) for all \(n \in \mathbb{N} \), so \(\lim_{n \to \infty} f_n^{\prime} (0) = 0 \). For \(x \neq 0\), we know 
\[
    f_n^{\prime} (x) = -2nx e^{-n^2 x^2}.
\]
Let \(y = nx\), then \(y \to \infty \) as \(n \to \infty \). Hence, \(f_n^{\prime} (x) = -2y e^{-y^2}\), and 
\[
    \lim_{n \to \infty} f_n^{\prime} (x) = \lim_{y \to \infty} -2y e^{-y^2} = 0.  
\]         
Hence, \(f_n^{\prime} \to 0\) pointwise. Now we know 
\[
    \sup _{x \in \mathbb{R} } \left\vert f_n^{\prime} (x) - 0 \right\vert = \sup _{x \in \mathbb{R} } \left\vert f_n^{\prime} (x) \right\vert. 
\] 
Define \(\varphi _n(x) = \left\vert f_n^{\prime} (x) \right\vert = 2n\vert x \vert e^{-n^2 x^2} \). Then, \(\varphi _n(x)\) is even, and thus we only need to study \(x > 0\). For \(x > 0\), \(\varphi _n(x) = 2nx e^{-n^2 x^2}\), and 
\[
    \varphi _n^{\prime} (x) = 2ne^{-n^2 x^2} + 2n \left( -2n^2 x \right) e^{-n^2 x^2} = 2ne^{-n^2 x^2} \left( 1 - 2n^2 x^2 \right).  
\]
Hence, \(\varphi _n^{\prime} (x) = 0\) iff \(1 - 2n^2 x^2 = 0\), so \(x = \frac{1}{\sqrt{2} n}\). Note that \(\varphi _n(x)\) decreases for \(x > \frac{1}{\sqrt{2}n }\), so \(\varphi _n \left( \frac{1}{\sqrt{2} n} \right) \) attains the maximum. Consider \(x_n = \frac{1}{\sqrt{2} n}\) if \((0, b] \subseteq I\) (or \(x_n = -\frac{1}{\sqrt{2} n}\) if \([-b, 0) \subseteq I\)). Thus, there exists \(N > 0\) s.t. \(\forall n \ge N\), \(x_n \in I\). Hence, 
\[
    \varphi _n \left( x_n \right) = \varphi \left( \frac{1}{\sqrt{2} n } \right) = \sqrt{2} e^{-\frac{1}{2}} \implies \sup _{x \in I} \left\vert f_n(x) \right\vert = \sqrt{2} e^{-\frac{1}{2}} \quad \forall n \ge N,    
\] and thus not uniformly convergent.                 
\end{proof}